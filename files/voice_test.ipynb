{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import tweepy\n",
    "\n",
    "# from elevenlabs import generate, play, set_api_key\n",
    "# from langchain.agents import initialize_agent, load_tools\n",
    "# from langchain.agents.agent_toolkits import ZapierToolkit\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.tools import BaseTool\n",
    "# from langchain.utilities.zapier import ZapierNLAWrapper\n",
    "\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs import Voice, VoiceSettings, play\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# set_api_key(os.getenv(\"ELEVEN_API_KEY\"))\n",
    "# openai.api_key = os.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set recording parameters\n",
    "duration = 5  # duration of each recording in seconds\n",
    "fs = 44100  # sample rate\n",
    "channels = 1  # number of channels\n",
    "\n",
    "\n",
    "def record_audio(duration, fs, channels):\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=channels)\n",
    "    sd.wait()\n",
    "    print(\"Finished recording.\")\n",
    "    return recording\n",
    "\n",
    "\n",
    "def transcribe_audio(recording, fs):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "        sf.write(temp_audio.name, recording, fs)\n",
    "        temp_audio.close()\n",
    "        with open(temp_audio.name, \"rb\") as audio_file:\n",
    "            # transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "            transcription = openai_client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\", \n",
    "                file=audio_file, \n",
    "                response_format=\"text\"\n",
    "            )\n",
    "        os.remove(temp_audio.name)\n",
    "    return transcription\n",
    "\n",
    "\n",
    "client = ElevenLabs(\n",
    "    api_key=os.getenv(\"XI_API_KEY\")  # Load API key from environment variable\n",
    ")\n",
    "\n",
    "def play_generated_audio(text):\n",
    "\n",
    "    # Generate the audio response using Eleven Labs API\n",
    "    # audio = client.generate(\n",
    "    #     text=text,\n",
    "    #     voice=\"Aria\",  # You can replace \"Aria\" with any other voice ID or name\n",
    "    #     model=\"eleven_multilingual_v2\",  # Specify the model version to use\n",
    "    #     stream=True,\n",
    "    #     voice_settings={\n",
    "    #         \"stability\": 0.8,  # Adjust stability (0.0 - 1.0)\n",
    "    #         \"similarity_boost\": 0.75  # Adjust the likeness to the selected voice\n",
    "    #     }\n",
    "    # )\n",
    "    # play(audio)\n",
    "    \n",
    "    response = openai_client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"nova\",\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    if hasattr(response, 'content') and response.content:\n",
    "        # Use your play function to play the audio instantly\n",
    "        play(response.content)\n",
    "    elif hasattr(response, 'url'):\n",
    "        # If the API provides a URL, use your play function to play the audio from URL\n",
    "        audio_url = response.url\n",
    "        play(audio_url)\n",
    "    else:\n",
    "        print(\"No valid audio content found in the response.\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_client.audio.speech.create(\n",
    "#     model=\"tts-1\",\n",
    "#     voice=\"alloy\",\n",
    "#     input=\"Hello, how are you?\"\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_2440\\4113104061.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press spacebar to start recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "You: Hej, hur mår du?\n",
      "\n",
      "Press spacebar to start recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "You: Üzgünüm adamım.\n",
      "\n",
      "Press spacebar to start recording.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPress spacebar to start recording.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mkeyboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# wait for spacebar to be pressed\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     recorded_audio \u001b[38;5;241m=\u001b[39m record_audio(duration, fs, channels)\n\u001b[0;32m     17\u001b[0m     message \u001b[38;5;241m=\u001b[39m transcribe_audio(recorded_audio, fs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\keyboard\\__init__.py:882\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(hotkey, suppress, trigger_on_release)\u001b[0m\n\u001b[0;32m    880\u001b[0m     lock \u001b[38;5;241m=\u001b[39m _Event()\n\u001b[0;32m    881\u001b[0m     remove \u001b[38;5;241m=\u001b[39m add_hotkey(hotkey, \u001b[38;5;28;01mlambda\u001b[39;00m: lock\u001b[38;5;241m.\u001b[39mset(), suppress\u001b[38;5;241m=\u001b[39msuppress, trigger_on_release\u001b[38;5;241m=\u001b[39mtrigger_on_release)\n\u001b[1;32m--> 882\u001b[0m     \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     remove_hotkey(remove)\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\keyboard\\__init__.py:117\u001b[0m, in \u001b[0;36m_Event.wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_UninterruptibleEvent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    118\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(name=\"gpt-4o\", temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "# zapier = ZapierNLAWrapper(zapier_nla_api_key=\"<ZAPIER_NLA_API_KEY>\")\n",
    "# toolkit = ZapierToolkit.from_zapier_nla_wrapper(zapier)\n",
    "\n",
    "# tools = [TweeterPostTool()] + toolkit.get_tools() + load_tools([\"human\"])\n",
    "\n",
    "# tools = toolkit.get_tools() + load_tools([\"human\"])\n",
    "\n",
    "# agent = initialize_agent(tools, llm, memory=memory, agent=\"conversational-react-description\", verbose=True)\n",
    "\n",
    "while True:\n",
    "    print(\"Press spacebar to start recording.\")\n",
    "    keyboard.wait(\"space\")  # wait for spacebar to be pressed\n",
    "    recorded_audio = record_audio(duration, fs, channels)\n",
    "    message = transcribe_audio(recorded_audio, fs)\n",
    "    print(f\"You: {message}\")\n",
    "    # assistant_message = agent.run(message)\n",
    "    assistant_message = llm.invoke(message).content\n",
    "    \n",
    "    play_generated_audio(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_curator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
