{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the graph chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'thread' from 'utils.chatbot_graph' (c:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\agent\\my-app\\app\\article-prep-agent\\v2\\implementations\\local_audio_chat_demo\\utils\\chatbot_graph.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchatbot_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m app, thread\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'thread' from 'utils.chatbot_graph' (c:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\agent\\my-app\\app\\article-prep-agent\\v2\\implementations\\local_audio_chat_demo\\utils\\chatbot_graph.py)"
     ]
    }
   ],
   "source": [
    "from utils.chatbot_graph import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The relations between Venezuela and Spain are currently strained. Tensions have increased due to Venezuela's arrest of an Argentine officer, which has also affected Spain because of previous similar incidents involving Spanish citizens. This situation is further complicated by Spain's recognition of an opposition candidate in Venezuela, which the Venezuelan government sees as interference. Historically, their relationship has been complex, often influenced by differing political ideologies.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"question\":\"current relations between Venezuela and Spain\"}, thread)[\"generation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking `chatbot_graph.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x1782f300910>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa = StateGraph(GraphState)\n",
    "\n",
    "# Add a node (action) to the graph\n",
    "wa.add_node(\"search_web\", search_web)\n",
    "\n",
    "# Set the entry point for the graph (optional, but typically useful for defining the start)\n",
    "wa.set_entry_point(\"search_web\")\n",
    "\n",
    "# Add an edge from the \"search_web\" node to the END node\n",
    "wa.add_edge(\"search_web\", END)\n",
    "\n",
    "# Compile the graph\n",
    "wa.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore.save_local(\"vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1b48ff36650>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import time\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langsmith import traceable\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "import json\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import END, StateGraph\n",
    "from tavily import TavilyClient, AsyncTavilyClient\n",
    "# tavily_async_client = AsyncTavilyClient()\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "from typing import Generator\n",
    "\n",
    "tavily_client = TavilyClient()\n",
    "\n",
    "@dataclass\n",
    "class StreamResponse:\n",
    "    content: str\n",
    "    additional_kwargs: Dict[str, Any]\n",
    "    response_metadata: Dict[str, Any]\n",
    "    id: str\n",
    "\n",
    "\n",
    "### State\n",
    "class SearchQueriesParams(BaseModel):\n",
    "    n_queries : int=Field(description=\"Number of queries to generate\")\n",
    "    \n",
    "    queries: List[str] = Field(\n",
    "        description=\"A list of strings representing the search queries to be executed.\",\n",
    "    )\n",
    "    tavily_days: List[Union[int, None]] = Field(\n",
    "        description=\"A list of integers representing the number of days to limit search results for each query (e.g., 7 for last week), or None for no time restriction. Each value corresponds to a query in the 'queries' list.\",\n",
    "    )\n",
    "    tavily_topic: List[str] = Field(\n",
    "        description=\"A list of strings indicating the type of search for each query: 'news' for time-sensitive queries or 'general' for unrestricted searches. Each value corresponds to a query in the 'queries' list.\",\n",
    "    )\n",
    "\n",
    "\n",
    "#we'll reference to this object very often to add new docs...etc\n",
    "    \n",
    "class GraphState(TypedDict):\n",
    "    news_summary : str \n",
    "    question : str\n",
    "    question_type : Union[str, str]\n",
    "    generation : str\n",
    "    web_search : Union[str, str] \n",
    "    search_queries_params : SearchQueriesParams\n",
    "    documents : str #the concatenated list of documents text content (or search results)\n",
    "    decission : str\n",
    "    feedback : Union[None, str]\n",
    "    iterations:int\n",
    "    streaming_avaiable:bool\n",
    "    response_stream : Generator[StreamResponse, None, None]\n",
    "    generation:str\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    \n",
    "    news_summary:str\n",
    "    question:str\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    \n",
    "    streaming_avaiable:bool\n",
    "    response_stream : Union[Generator[StreamResponse, None, None], None]\n",
    "    generation:Union[str, None]\n",
    "    \n",
    "\n",
    "# Check if the directory and files are readable\n",
    "directory = './rag_docs'\n",
    "# print(os.access(directory, os.R_OK))  # Checks if the directory is readable\n",
    "os.chmod('./rag_docs', 0o755)\n",
    "\n",
    "\n",
    "markdown_folder_path = \"./rag_docs\"  # Set the path to your folder\n",
    "documents = []\n",
    "\n",
    "# Iterate over all .md files in the directory\n",
    "for file in os.listdir(markdown_folder_path):\n",
    "    if file.endswith('.md'):\n",
    "        markdown_path = os.path.join(markdown_folder_path, file)                     #=fast\n",
    "        loader = UnstructuredMarkdownLoader(markdown_path, mode=\"single\", strategy=\"precise\")\n",
    "        documents.extend(loader.load())  # Add loaded documents to the list\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200, chunk_overlap=100, add_start_index=True #starting char pos.\n",
    "    #size of characters for each chunk\n",
    "    #2nd param: will let us have a little portion of the prev. chunk\n",
    "    # so in case the key info is in that chunk, we can have a way to get those prev chars if needed \n",
    "    \n",
    "    #\n",
    ")\n",
    "all_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "#the so-called chroma database\n",
    "local_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "persist_dir = \"./chroma_db\"\n",
    "os.makedirs(persist_dir, exist_ok=True)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings,\n",
    "                                    persist_directory=persist_dir)\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3},\n",
    "                                    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "llm_json = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature = 0,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
    "\n",
    "\n",
    "#---------------------\n",
    "#prompts\n",
    "\n",
    "#TODO: we are trying to address the case where it gets an input question which is missleading\n",
    "docs_answer_generation_instructions = \"\"\"\n",
    "You are an assistant for question-answering tasks inside a phone call conversation.\n",
    "\n",
    "Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Keep the answer concise and optimized to reduce latency, in a spoken language style.\n",
    "\n",
    "If provided, there will be a separate message with feedback about what to improve from the previous generation attempt. Use this feedback to enhance your response while maintaining grounding in the provided context.\n",
    "\n",
    "Additionally, evaluate whether the provided context contradicts, corrects, or invalidates the user's question. If you are 100% certain that the question is misleading, incorrect, or based on faulty assumptions, use the context to explain why the question is problematic and provide the correct information. In such case, justify your answer with explicit references to the context. \n",
    "\n",
    "You must also keep in mind that you're answering questions related to either the news of the week, current issues, or historical questions, so always respond appropriately by connecting your answer to the spoken topics, which I'll attach below as a brief summary.\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "\n",
    "Remember: \n",
    "- Only correct or challenge the user's question when the context provides indisputable evidence to do so. Otherwise, answer normally.\n",
    "- If feedback was provided, ensure your response addresses all the improvement points while staying faithful to the context.\n",
    "\"\"\"\n",
    "\n",
    "query_writer_instructions = \"\"\"\n",
    "Given the user's background and the question provided below, generate an appropriate number (n) of relevant queries to search on the internet in order to gather sufficient information to answer the question.\n",
    "You can generate a maximum of 2 queries. Be sure you provide a precisse amount of queries to have a fast and accurate result, don't search more than needed.\n",
    "\n",
    "If provided, there will be a separate message with feedback about why previous queries were not useful. Use this feedback to avoid similar issues and generate more effective queries.\n",
    "\n",
    "**Current Date**: {current_date}\n",
    "\n",
    "**Important Note**: A separate message includes a list of previously searched queries (`searched_queries`). Consider these queries and evaluate why they may not have been useful (e.g., irrelevant results, overly broad/narrow focus, or failure to address the question fully). Use this evaluation and any provided feedback to refine, reformulate, or supplement the queries to ensure better results. If no `searched_queries` are provided, proceed without them.\n",
    "\n",
    "**Datetime Marker Awareness**:  \n",
    "When generating queries, use datetime markers only if appropriate to the query context:\n",
    "\n",
    "1. **Time-Sensitive or Current Events (`tavily_topic=\"news\" and tavily_days=7`)**:  \n",
    "   - **Do not include any explicit datetime markers** (e.g., \"2025\" or \"January 2025\") in the search query, as `tavily_days=7` already ensures the query focuses on recent results.  \n",
    "   - If the user's question explicitly includes time hints (e.g., \"yesterday,\" \"last week\"), calculate the corresponding date relative to **Current Date** (e.g., \"yesterday\" = `{current_date} - 1 day`) and use this date in the query.  \n",
    "   - Otherwise, avoid adding datetime markers for time-sensitive queries, as they are unnecessary and may limit search results.  \n",
    "\n",
    "2. **General or Historical Topics (`tavily_topic=\"general\" and tavily_days=None`)**:  \n",
    "   - Include datetime markers only when they clarify the query or provide precision (e.g., \"economic crisis Spain 2008\").  \n",
    "   - Avoid unnecessary datetime markers for well-known historical events (e.g., \"Battle of Lepanto\"), as the event is self-contained in history.  \n",
    "\n",
    "3. **Redundancy**: Ensure datetime markers are added only if needed for precision based on the query context and `tavily` parameters.  \n",
    "\n",
    "Failure to follow these guidelines may result in ineffective or overly narrow queries.\n",
    "\n",
    "### Query Complexity and Necessity:\n",
    "- If the question is straightforward (e.g., \"What is the capital of Spain?\"), generate a single query.\n",
    "- For more complex or multi-faceted questions, generate multiple queries to ensure all relevant aspects are covered without redundancy.\n",
    "- If feedback was provided, adjust query specificity and coverage accordingly.\n",
    "\n",
    "Renember to not use 2 queries unless you're completely sure it's needed such amount.\n",
    "\n",
    "For each query, you must specify these parameters:\n",
    "### Tavily-Specific Web Search Parameters:\n",
    "For each query, set the Tavily parameters as follows:\n",
    "- **tavily_topic**:  \n",
    "   - Use `\"news\"` if the query is related to time-sensitive or current events.  \n",
    "   - Use `\"general\"` for technical, historical, or non-time-sensitive topics.  \n",
    "- **tavily_days**:  \n",
    "   - Set `7` only if `tavily_topic=\"news\"`.  \n",
    "   - Set `None` if `tavily_topic=\"general\"`.\n",
    "---\n",
    "**User question**: {question}\n",
    "\"\"\"\n",
    "\n",
    "docs_grader_instructions = \"\"\"\n",
    "\n",
    "    You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "generation_grader_instructions = \"\"\"\n",
    "\n",
    "You are a grader assessing whether an answer is grounded in or supported by a set of facts. Additionally, evaluate whether the answer correctly identifies and explicitly addresses any misleading or incorrect assumptions in the user's question, based on the provided facts.\n",
    "\n",
    "If the answer correctly identifies and addresses such misleading or incorrect assumptions, assign a `\"yes\"` to the `score` key, even if the user's question contains inaccuracies.\n",
    "\n",
    "For example:\n",
    "- Question: \"Who was Fernando Hitler?\"\n",
    "  * Incorrect Assumption: The name \"Fernando Hitler\" is historically inaccurate.\n",
    "  * Correct Response: Clarifies that no person named Fernando Hitler exists in historical records and offers accurate information about Adolf Hitler if relevant.\n",
    "  * Outcome: Score \"yes\" because the response correctly addresses the misleading premise.\n",
    "\n",
    "Your task:\n",
    "1. Determine whether the answer is factually grounded and addresses misleading or incorrect assumptions.\n",
    "2. If the answer successfully corrects such assumptions and provides a grounded response, score `\"yes\"`.\n",
    "3. If the answer fails, provide feedback to improve it.\n",
    "\n",
    "Provide your assessment as a JSON with:\n",
    "- A 'score' key with value 'yes' or 'no'\n",
    "- If the score is 'no', include a 'feedback' string key with specific guidance on:\n",
    "  * Identifying and addressing misleading assumptions.\n",
    "  * Correcting factual errors or omissions.\n",
    "  * Enhancing clarity and conciseness.\n",
    "  * Aligning with weekly news context if applicable.\n",
    "\n",
    "Here are the facts:\n",
    "\\n ------- \\n\n",
    "{documents}\n",
    "\\n ------- \\n\n",
    "\n",
    "Here is the generated answer:\n",
    "\\n ------- \\n\n",
    "{generation}\n",
    "\\n ------- \\n\n",
    "\n",
    "Respond only with the JSON object, no explanation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "answer_grader_instructions = \"\"\"\n",
    "You are a grader assessing whether an answer is useful and effectively resolves the user's question. Additionally, evaluate whether the answer appropriately challenges and corrects any misleading or incorrect assumptions in the question, if the context justifies such corrections.\n",
    "\n",
    "If the answer correctly identifies and addresses such misleading assumptions, assign a `\"yes\"` to the `score` key, even if the user's question contains inaccuracies.\n",
    "\n",
    "For example:\n",
    "- Question: \"Who was Fernando Hitler?\"\n",
    "  * Incorrect Assumption: The name \"Fernando Hitler\" is historically inaccurate.\n",
    "  * Correct Response: Clarifies that no individual named Fernando Hitler exists in historical records, redirecting the user to relevant facts about Adolf Hitler if applicable.\n",
    "  * Outcome: Score \"yes\" because the response correctly addresses the misleading premise.\n",
    "\n",
    "Your task:\n",
    "1. Evaluate whether the answer resolves the user's question and identifies misleading assumptions when applicable.\n",
    "2. If the answer successfully corrects these issues and is useful, score `\"yes\"`.\n",
    "3. If the answer fails, provide feedback on how it can improve.\n",
    "\n",
    "### Specific Evaluation Criteria for Query Generation:\n",
    "If the user's question pertains to **time-sensitive or current events**, and:\n",
    "1. The generated queries incorrectly use explicit datetime markers (e.g., \"January 2025\") despite `tavily_days=7` and `tavily_topic=\"news\"`, assign `\"no\"` to the `score` key.\n",
    "2. If the user's question does not include any explicit temporal hints (e.g., \"yesterday\"), and the queries still include unnecessary datetime markers, this is a misuse and warrants `\"no\"`.\n",
    "3. If the answer does not appropriately tailor queries to the user's question (e.g., redundant or overly broad), assign `\"no\"`.\n",
    "\n",
    "When assigning a `\"no\"` score, provide detailed and actionable feedback under the `feedback` key to ensure the query generation improves. Your feedback should:\n",
    "- Highlight the improper use of datetime markers if applicable.\n",
    "- Suggest excluding datetime markers when `tavily_days=7` and the question lacks explicit temporal hints.\n",
    "- Emphasize aligning query parameters (e.g., `tavily_topic` and `tavily_days`) with the user's question context.\n",
    "- Recommend clearer or more precise query formulations to address the user's needs.\n",
    "\n",
    "### Additional Context:\n",
    "- **Already Searched Queries**: You will receive the list of already searched queries as a separate message below. Use this information to evaluate whether the generated queries address gaps, improve upon previous attempts, and avoid redundant or ineffective formulations.\n",
    "\n",
    "Provide your assessment as a JSON with:\n",
    "- A `score` key with value `\"yes\"` or `\"no\"`.\n",
    "- If the score is `\"no\"`, include a `feedback` key focusing on:\n",
    "  * Addressing improper datetime marker usage.\n",
    "  * Improving query clarity and relevance.\n",
    "  * Adhering to `tavily` parameter requirements.\n",
    "  * Filling gaps in information and tailoring to the userâ€™s question.\n",
    "\n",
    "Here is the generated answer:\n",
    "\\n ------- \\n\n",
    "{generation}\n",
    "\\n ------- \\n\n",
    "\n",
    "Here is the original user question:\n",
    "\\n ------- \\n\n",
    "{question}\n",
    "\\n ------- \\n\n",
    "\n",
    "Here are the already searched queries:\n",
    "\\n ------- \\n\n",
    "{searched_queries}\n",
    "\\n ------- \\n\n",
    "\n",
    "Respond only with the JSON object, no explanation.\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "@traceable\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    # print(\"---RETRIEVE---\")\n",
    "    i = time.time()\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    \n",
    "    context = ' '.join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    e = time.time()\n",
    "    \n",
    "    print(\"retrieve(): \", e-i, \" secs\")\n",
    "    \n",
    "    return {\"documents\": context, \"question\": question}\n",
    "#\n",
    "\n",
    "@traceable\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    context = state[\"documents\"]\n",
    "    \n",
    "    \n",
    "    i = time.time()\n",
    "\n",
    "    system_instructions = docs_grader_instructions.format(question=question, document=context)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_instructions},\n",
    "        # {\"role\": \"user\", \"content\": f\": {}\"}\n",
    "    ]   \n",
    "    \n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            temperature = 0,\n",
    "            model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
    "\n",
    "    \n",
    "    #llm_json\n",
    "    grade = json.loads(model.invoke(messages).content)[\"score\"]\n",
    "    # print(grade)\n",
    "    \n",
    "    e = time.time()\n",
    "\n",
    "    print(\"grade_documents(): \", e-i, \" seconds\")\n",
    "    \n",
    "    if grade.lower() == \"yes\":\n",
    "        # print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "        return {\"documents\": context, \"question\": question, \"web_search\": \"No\"}\n",
    "    else:\n",
    "        # print(\"---GRADE: RETRIEVED DOCUMENTS NOT RELEVANT, RUNNING WEB SEARCH INSTEAD---\")\n",
    "        return {\"documents\": context, \"question\": question, \"web_search\": \"Yes\"}\n",
    "\n",
    "\n",
    "@traceable\n",
    "def handle_trivial_question(state:InputState):\n",
    "    \"\"\"\n",
    "    Determines whether the question is trivial or irrelevant to run RAG or websearch.\n",
    "    Uses an LLM to classify the question as \"is_trivial\" or \"not_trivial\".\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    \n",
    "    Returns:\n",
    "        state (dict): Updated state with the classification (\"is_trivial\" or \"not_trivial\").\n",
    "    \"\"\"\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # LLM prompt to classify the question as trivial or not\n",
    "    trivial_classification_instructions = \"\"\"\n",
    "    You are an AI chatbot. Classify the user's question as either \"is_trivial\" or \"not_trivial\". \n",
    "    The question is considered \"trivial\" if it is a greeting, a simple personal question (e.g., \"What's your name?\"), \n",
    "    , incomplete or missleading questions, or if it doesn't require to search for detailed information to answer.\n",
    "    If the question is a valid request for information or involves specific queries that require processing or websearch, \n",
    "    classify it as \"not_trivial\".\n",
    "    \n",
    "    Example trivial questions: \n",
    "    - \"Hello\"\n",
    "    - \"What's your name?\"\n",
    "    - \"How are you?\"\n",
    "    \n",
    "    Example non-trivial questions:\n",
    "    - \"Tell me the latest news on AI\"\n",
    "    - \"What is the capital of France?\"\n",
    "    - \"How does a neural network work?\"\n",
    "    \n",
    "    Question: {question}\n",
    "    Please respond with either \"is_trivial\" or \"not_trivial\", no preambles or explanations\n",
    "    \"\"\"\n",
    "\n",
    "    i = time.time()\n",
    "\n",
    "    # Create the system message with the classification instructions and the question\n",
    "    system_instructions = trivial_classification_instructions.format(question=question)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_instructions},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "    ]    \n",
    "\n",
    "    model = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            temperature = 0)\n",
    "            # model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
    "\n",
    "    # Get the classification from the LLM\n",
    "    decission = model.invoke(messages).content.lower()\n",
    "    #llm\n",
    "    \n",
    "    e = time.time()\n",
    "\n",
    "    print(\"handle_trivial_question(): \", e-i, \" seconds\")\n",
    "    \n",
    "    if decission == \"is_trivial\":\n",
    "        return {\"question\": question, \"question_type\": \"is_trivial\", \"iterations\":0}\n",
    "    \n",
    "    elif decission == \"not_trivial\":\n",
    "        return {\"question\": question, \"question_type\": \"not_trivial\", \"iterations\":0}\n",
    "    \n",
    "    \n",
    "@traceable\n",
    "def answer_trivial_question(state):\n",
    "    \"\"\"\n",
    "    Handle trivial or irrelevant questions by using an LLM to generate a response.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        state (dict): Updated state with a response to the trivial question.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Trivial question generation instructions\n",
    "    # trivial_answer_generation_instructions = \"\"\"\n",
    "    # You are an AI chatbot. \n",
    "    # \"\"\"\n",
    "\n",
    "    # # Send the question and instructions to the LLM to generate a response\n",
    "    # system_instructions = trivial_answer_generation_instructions + f\"User's question: {question}\"\n",
    "\n",
    "    # messages = [\n",
    "    #     {\"role\": \"system\", \"content\": system_instructions},\n",
    "    #     {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "    # ]    \n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI chatbot answering a user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "    ]    \n",
    "\n",
    "    # Call the LLM to generate the response\n",
    "    # response = llm.with_config().invoke(messages)\n",
    "    \n",
    "    # response = llm.invoke(messages)\n",
    "    \n",
    "    i = time.time()\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature = 0,\n",
    "            max_completion_tokens=50)\n",
    "            # model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
    "\n",
    "    response_stream = model.stream(messages, max_completion_tokens=500,\n",
    "                                 temperature=0)\n",
    "    #llm\n",
    "    e = time.time()\n",
    "\n",
    "    print(\"answer_trivial_question(): \", e-i, \" seconds\")\n",
    "    \n",
    "    # response.id = \"final_pred\"\n",
    "    # Return the state with the generated response for trivial question\n",
    "    return {\"question\": question, \"streaming_avaiable\": True, \"response_stream\":response_stream, \"generation\":None}\n",
    "#                                               #we put the generation key (final answer) in the state\n",
    "    \n",
    "\n",
    "@traceable\n",
    "def answer_with_docs(state):\n",
    "    \"\"\"\n",
    "    Generate answer either using RAG on retrieved documents or web search results\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    # print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    context = state[\"documents\"]\n",
    "    \n",
    "    feedback = state.get(\"feedback\", None)\n",
    "    \n",
    "    i = time.time()\n",
    "\n",
    "    system_instructions = docs_answer_generation_instructions.format(question=question, context=context)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_instructions},\n",
    "        #todo: check if this additional param is necessary\n",
    "        {\"role\": \"user\", \"content\": f\": Here is the news summary shown to the user before: {state['news_summary']}\"},\n",
    "        {\"role\":\"user\", \"content\":f\"Here is some feedback (if applicable): {feedback}\"}\n",
    "    ]   \n",
    "                            #gpt3.5-turbo\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) \n",
    "\n",
    "    \n",
    "    #llm\n",
    "    answer = model.invoke(messages, max_tokens=150, temperature=0.1) #.response lo quitamos\n",
    "    \n",
    "    e = time.time()\n",
    "\n",
    "    print(\"answer_with_docs(): \", e-i, \" seconds\")\n",
    "    \n",
    "    return {\"documents\": context, \"question\": question, \"generation\": answer,\n",
    "            \"streaming_avaible\":False}\n",
    "    #for now, streaming won't be avaiable in this node given that the generation is reviewed afterwards\n",
    "    #that means that we need to have the entire generation for that, so we can't directly stream the output\n",
    "    #and also, because it can get a 2nd revision (max_iterations=2)\n",
    "#\n",
    "\n",
    "@traceable\n",
    "def generate_queries(state):\n",
    "    \"\"\" Generate search queries for a report section, and set tavily_topic and tavily_days\"\"\"\n",
    "\n",
    "    i = time.time()\n",
    "    \n",
    "    feedback = state.get(\"feedback\", None)\n",
    "    \n",
    "    # Generate queries and tavily params with the custom pydantic model\n",
    "\n",
    "                        #gpt4o-mini , gpt4-turbo\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) \n",
    "\n",
    "    structured_llm = model.with_structured_output(SearchQueriesParams)\n",
    "                    #llm.\n",
    "                    \n",
    "    #already searched queries    \n",
    "    searched_queries = state.get(\"search_queries_params\", None) #looking for already searched queries\n",
    "    \n",
    "    \n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "# Format it as a string (optional, e.g., 'YYYY-MM-DD HH:MM:SS')\n",
    "    current_datetime_str = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Format system instructions                   #instead of number_of_queries=3, now it also decides such number\n",
    "    system_instructions = query_writer_instructions.format(question=state[\"question\"],\n",
    "                                                           current_date=current_datetime_str,\n",
    "                                                        )\n",
    "\n",
    "    print(f\"already searched queries (if applicable): {searched_queries}\")\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_instructions},\n",
    "                {\"role\":\"user\", \"content\":f\"feedback (if applicable): {feedback}\"}]\n",
    "    \n",
    "    if searched_queries is not None:\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"already searched queries (if applicable): {searched_queries}\"})\n",
    "\n",
    "\n",
    "    search_params = structured_llm.invoke(messages)\n",
    "    \n",
    "    n_queries = search_params.n_queries\n",
    "    queries = search_params.queries  # Assuming 'queries' is the result you expect from the LLM response\n",
    "    tavily_topic = search_params.tavily_topic  # LLM response for tavily_topic\n",
    "    tavily_days = search_params.tavily_days\n",
    "    \n",
    "    search_queries_params = SearchQueriesParams(\n",
    "        n_queries=n_queries,\n",
    "        queries=queries,\n",
    "        tavily_topic=tavily_topic,\n",
    "        tavily_days=tavily_days\n",
    "    )\n",
    "    \n",
    "    e = time.time()\n",
    "    print(\"Elapsed time generate_queries(): \", e-i, \" seconds\")\n",
    "    return {\"search_queries_params\": search_queries_params}\n",
    "\n",
    "\n",
    "#TODO: we need to make all the graph either async or sync, not mixed , see https://github.com/langchain-ai/langgraph/issues/2928#issuecomment-2569915286\n",
    "\n",
    "#TODO NOTE: we have selected to get n=3 results per query call (maybe we should try setting it to 1 to reduce latency)\n",
    "#or keeping such amount to ensure it retrieves trustworthy sources\n",
    "\n",
    "def tavily_search_sync(search_queries:List[str], tavily_topics:List[str], tavily_days=List[Union[str, None]]):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    search_docs = []\n",
    "\n",
    "    \n",
    "    for ix, query in enumerate(search_queries):\n",
    "        \n",
    "        # print(query)\n",
    "        if tavily_topics[ix] == \"news\":\n",
    "            \n",
    "            # print(\"gonna search \", tavily_topics[ix])\n",
    "            result = tavily_client.search(  \n",
    "                query,\n",
    "                days=tavily_days[ix], #always 7 (for now)\n",
    "                topic=\"news\", \n",
    "                max_results=1 #todo: ---> DECIDE THE NUMBER OF RESULTS\n",
    "                # include_raw_content=True,\n",
    "               \n",
    "            )\n",
    "        else:\n",
    "            result = tavily_client.search(  \n",
    "                query,\n",
    "                topic=\"general\", \n",
    "                max_results=1 #todo: ---> DECIDE THE NUMBER OF RESULTS\n",
    "                # include_raw_content=True,\n",
    "               \n",
    "            )\n",
    "            \n",
    "        search_docs.append(result)\n",
    "\n",
    "    return search_docs\n",
    "\n",
    "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):\n",
    "    \"\"\"\n",
    "    Takes either a single search response or list of responses from Tavily API and formats them.\n",
    "    Limits the raw_content to approximately max_tokens_per_source.\n",
    "    include_raw_content specifies whether to include the raw_content from Tavily in the formatted string.\n",
    "    \n",
    "    Args:\n",
    "        search_response: Either:\n",
    "            - A dict with a 'results' key containing a list of search results\n",
    "            - A list of dicts, each containing search results\n",
    "            \n",
    "    Returns:\n",
    "        str: Formatted string with deduplicated sources\n",
    "    \"\"\"\n",
    "    # Convert input to list of results\n",
    "    if isinstance(search_response, dict):\n",
    "        # sources_list = search_response['results']\n",
    "        sources_list = search_response.get('results', [])\n",
    "        \n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                # sources_list.extend(response['results'])\n",
    "                sources_list.extend(response.get('results', []))\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "    \n",
    "    # Deduplicate by URL\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        url = source.get('url')\n",
    "        # if source['url'] not in unique_sources:\n",
    "        #     unique_sources[source['url']] = source\n",
    "        if url and url not in unique_sources:\n",
    "            unique_sources[url] = source\n",
    "    \n",
    "    # Format output\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for i, source in enumerate(unique_sources.values(), 1):\n",
    "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if include_raw_content:\n",
    "            # Using rough estimate of 4 characters per token\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            # Handle None raw_content\n",
    "            raw_content = source.get('raw_content', '')\n",
    "            if raw_content is None:\n",
    "                raw_content = ''\n",
    "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
    "                \n",
    "    return formatted_text.strip()\n",
    "\n",
    "\n",
    "def search_web(state):\n",
    "    \"\"\" Web search based based on the question.\"\"\"\n",
    "    \n",
    "    # Get search_queries_params from state (which includes lists of queries, tavily_topic, and tavily_days)\n",
    "     \n",
    "    search_queries_params = state[\"search_queries_params\"]\n",
    "    n_queries = search_queries_params.n_queries  # Number of queries to generate\n",
    "    queries = search_queries_params.queries  # List of queries\n",
    "    tavily_topics = search_queries_params.tavily_topic  # List of topics ('news' or 'general')\n",
    "    tavily_days = search_queries_params.tavily_days  # List of days for limiting search (or None)\n",
    "\n",
    "    print(f\"gonna generate {n_queries} queries\")\n",
    "    # Check if lengths of queries, tavily_topics, and tavily_days are equal\n",
    "    if not (n_queries == len(queries) == len(tavily_topics) == len(tavily_days)):\n",
    "        raise ValueError(\"The lengths of queries, tavily_topics, and tavily_days must be equal.\")\n",
    "    \n",
    "    # Web search using async function with corresponding parameters\n",
    "    # for query, topic, days in zip(queries, tavily_topics, tavily_days):\n",
    "    #     search_doc = tavily_search_sync([query], topic, days)  # Replace with synchronous function\n",
    "    #     search_docs.extend(search_doc)  # Add results to the overall list\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = tavily_search_sync(search_queries=queries, tavily_topics=tavily_topics, tavily_days=tavily_days)\n",
    "    \n",
    "    \n",
    "    # Deduplicate and format sources                                             #1000 -- check annotations whasap\n",
    "    source_str = deduplicate_and_format_sources(response, max_tokens_per_source=5000, include_raw_content=True)\n",
    "\n",
    "    web_results = Document(page_content=source_str,\n",
    "                           \n",
    "                        metadata={\"source\": \"Tavily Web Search\"} )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"[*] Elapsed time for search: \", (end_time-start_time))\n",
    "    #we'll also add to the vectorstore the websearch results so next time it won't need to run web search again for specific questions\n",
    "    vectorstore.add_documents([web_results])\n",
    "    \n",
    "    return {\"documents\": web_results.page_content}\n",
    "\n",
    "@traceable\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generated response is grounded in the document and answers the question.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    context = state[\"documents\"] #it can be either the retrieved docs or the web search results\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    i = time.time()\n",
    "\n",
    "    \n",
    "    n_iterations = state.get(\"iterations\",None)\n",
    "    \n",
    "    if n_iterations!=None:\n",
    "        n_iterations+=1\n",
    "    else:\n",
    "        n_iterations=1\n",
    "        \n",
    "        # force_stop = state.get(\"force_stop\",None)\n",
    "    if n_iterations==2:\n",
    "        return {\"decission\":\"force_stop\", \"feedback\":None,\n",
    "                \"generation\":state[\"generation\"]}\n",
    "        \n",
    "        \n",
    "    generation_grader_prompt = generation_grader_instructions.format(documents=context, generation=generation)\n",
    "    \n",
    "    already_searched_queries = state.get(\"search_queries_params\", None)                                                               \n",
    "   \n",
    "    answer_grader_prompt = answer_grader_instructions.format(generation=generation, question=question,\n",
    "                                                             searched_queries=f\"already searched queries: if applicable: {already_searched_queries}\")\n",
    "    \n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": generation_grader_prompt},\n",
    "        # {\"role\": \"user\", \"content\": f\": {}\"}\n",
    "    ]   \n",
    "    \n",
    "    \n",
    "    \n",
    "    # llm = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "    model = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature = 0,\n",
    "            model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
    "\n",
    "\n",
    "    #todo: instead of using llm_json\n",
    "    response = json.loads(model.invoke(messages).content)\n",
    "    #note: faster model\n",
    "    \n",
    "        \n",
    "    # print(grade)\n",
    "    # print(\"Generation grader output json:\", response)\n",
    "  \n",
    "  #----------------  \n",
    "    if response[\"score\"].lower() == \"yes\": #the answer is grounded in the documents\n",
    "        \n",
    "    \n",
    "        #now, we check such generation correctly answers the question\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": answer_grader_prompt},\n",
    "            # {\"role\": \"user\", \"content\": f\": {}\"}\n",
    "        ]   \n",
    "        \n",
    "        model = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature = 0,\n",
    "            model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
    " \n",
    "        \n",
    "        #note: llm_json.invoke()\n",
    "        response = json.loads(model.invoke(messages).content)\n",
    "        # print(\"answer grader output json:\", response)\n",
    "        # print(type(response))\n",
    "        \n",
    "        \n",
    "        if response[\"score\"].lower() == \"yes\":\n",
    "            \n",
    "            e = time.time()\n",
    "            \n",
    "            print(\"grade_documents_v_questiom(): \", e-i, \" seconds\")\n",
    "            # print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS, AND IT ANSWERS THE QUESTION---\")\n",
    "            # return \"useful\"\n",
    "            return {\"decission\":\"useful\", \"feedback\":None, \"iterations\":n_iterations, #si es useful, acaba\n",
    "                    \"generation\":generation, \"streaming_avaiable\":False, \"response_stream\":None}\n",
    "            \n",
    "            \n",
    "                                #para que una respuesta sea buena\n",
    "                                #debera acabar siendo = None\n",
    "                                #por lo que un nodo no tomara feedback que no le corresponde\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            e = time.time()\n",
    "            \n",
    "            print(\"grade_documents_v_questiom(): \", e-i, \" seconds\")\n",
    "            # print(\"---DECISION: GENERATION DOES NOT ANSWER THE QUESTION, RUNNING WEBSEARCH---\")\n",
    "            # return \"not_useful\" #then we simply retry the websearch (only)\n",
    "            return {\"decission\":\"not_useful\", \"feedback\":response[\"feedback\"],\n",
    "                    \"iterations\":n_iterations, \"generation\":generation, \"streaming_avaiable\":False, \"response_stream\":None}\n",
    "            \n",
    "    else:\n",
    "        #IF THE MODEL HALLUCINATES, WE RE-RUN ONLY THE GENERATION\n",
    "        \n",
    "        # print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        # return \"not_grounded\"\n",
    "        \n",
    "        e = time.time()\n",
    "            \n",
    "        print(\"grade_documents_v_questiom(): \", e-i, \" seconds\")\n",
    "    \n",
    "\n",
    "        return {\"decission\":\"not_grounded\", \"feedback\":response[\"feedback\"],\n",
    "                \"iterations\":n_iterations, \"generation\":generation, \"streaming_avaiable\":False}\n",
    "    \n",
    "    \n",
    "def process_final_pred(state):\n",
    "    \n",
    "    n_iterations = state[\"iterations\"] #we don't want to surpass the iterations limit\n",
    "    decission = state[\"decission\"]\n",
    "    \n",
    "    if decission == \"useful\" or n_iterations==2:\n",
    "        last_pred = state[\"generation\"]\n",
    "        \n",
    "        last_pred.id = \"last_pred\"\n",
    "        \n",
    "        state[\"generation\"] = last_pred #ensure last pred have this unique id\n",
    "#-------------------- graph\n",
    "    \n",
    "workflow = StateGraph(GraphState, input=InputState, output=OutputState)\n",
    "# Define the nodes\n",
    "workflow.add_node(\"handle_trivial_question\", handle_trivial_question)\n",
    "workflow.add_node(\"answer_trivial_question\", answer_trivial_question) \n",
    "workflow.add_node(\"retrieve\", retrieve) \n",
    "workflow.add_node(\"generate_queries\", generate_queries)\n",
    "workflow.add_node(\"websearch\", search_web)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"answer_with_docs\", answer_with_docs)\n",
    "workflow.add_node(\"grade_generation_v_documents_and_question\", grade_generation_v_documents_and_question)\n",
    "workflow.add_node(\"detect_if_final_pred\", process_final_pred)\n",
    "\n",
    "\n",
    "#conditional nodes\n",
    "def detect_trivial_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the question is trivial or not\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "    question_type = state[\"question_type\"]\n",
    "    # if question_type == \"is_trivial\":\n",
    "    #     return \"answer_trivial_question\"\n",
    "    # else:\n",
    "    #     return \"retrieve\"\n",
    "    return question_type\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    web_search = state[\"web_search\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        return \"use_websearch\"\n",
    "    else:\n",
    "        return \"answer_with_docs\"\n",
    "    \n",
    "\n",
    "workflow.set_entry_point(\"handle_trivial_question\")\n",
    "\n",
    "workflow.add_conditional_edges(\"handle_trivial_question\",\n",
    "                               detect_trivial_question,\n",
    "                               {\"is_trivial\": \"answer_trivial_question\", \"not_trivial\": \"retrieve\"})\n",
    "\n",
    "workflow.add_edge(\"answer_trivial_question\", END)\n",
    "\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate, #after running grade_documents, we get the key of websearch to know if we run it or not\n",
    "    {\n",
    "        \"use_websearch\": \"generate_queries\", #before websearch, we generate the queries through the generate_queries node\n",
    "        \"answer_with_docs\": \"answer_with_docs\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"generate_queries\", \"websearch\") \n",
    "workflow.add_edge(\"websearch\", \"answer_with_docs\") #after web search, we go directly to generation\n",
    "# workflow.add_edge(\"answer_with_docs\", \"handle_trivial_question\")\n",
    "workflow.add_edge(\"answer_with_docs\", \"grade_generation_v_documents_and_question\")\n",
    "workflow.add_edge(\"grade_generation_v_documents_and_question\",\"detect_if_final_pred\")\n",
    "\n",
    "\n",
    "# workflow.add_conditional_edges( #conditional edges\n",
    "#     \"answer_with_docs\",\n",
    "#     grade_generation_v_documents_and_question,\n",
    "#     {\n",
    "#         \"not_grounded\": \"answer_with_docs\", #if the llm generation grader result is = \"not supported\", then re-try\n",
    "#         \"useful\": END, #if it is useful, then end the process\n",
    "#         \"not_useful\": \"generate_queries\", #if not useful, then re-create queries again given the previous one (if applicable) and run websearch\n",
    "#     },\n",
    "# )\n",
    "\n",
    "\n",
    "def check_generation(state):\n",
    "    \n",
    "    \n",
    "    if state[\"decission\"] == \"useful\":\n",
    "        \n",
    "        # state[\"streaming_avaiable\"] = False\n",
    "        \n",
    "        return \"useful\"\n",
    "    \n",
    "    elif state[\"decission\"] == \"not_useful\":\n",
    "        \n",
    "        # state[\"streaming_avaiable\"] = False\n",
    "\n",
    "        \n",
    "        return \"not_useful\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif state[\"decission\"] == \"not_grounded\":\n",
    "        \n",
    "        #doesnt work\n",
    "        # state[\"streaming_avaiable\"] = False\n",
    "\n",
    "        \n",
    "        return \"not_grounded\"\n",
    "    \n",
    "    elif state[\"decission\"] == \"force_stop\":\n",
    "        \n",
    "        print(\"forcing stop of the graph...\")\n",
    "        # state[\"streaming_avaiable\"] = False\n",
    "        \n",
    "        \n",
    "        return \"force_stop\"\n",
    "    \n",
    "    \n",
    "    print(\"current feedback provided \", state[\"feedback\"])\n",
    "        \n",
    "    \n",
    "workflow.add_conditional_edges( #conditional edges\n",
    "    \"grade_generation_v_documents_and_question\",\n",
    "    check_generation,\n",
    "    {\n",
    "        \"not_grounded\": \"answer_with_docs\", #if the llm generation grader result is = \"not supported\", then re-try\n",
    "        \"useful\": END, #if it is useful, then end the process\n",
    "        \"not_useful\": \"generate_queries\", #if not useful, then re-create queries again given the previous one (if applicable) and run websearch,\n",
    "        \"force_stop\":END\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------- compiling the graph\n",
    "\n",
    "#todo: check if short term and long term memmory are useful\n",
    "#todo: redefine the node of web search to generate multiple queries given the question (add tavily_days and tavily_topic too)\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from contextlib import ExitStack\n",
    "\n",
    "stack = ExitStack()\n",
    "memory = stack.enter_context(SqliteSaver.from_conn_string(\":memory:\"))\n",
    "\n",
    "app = workflow.compile() #checkpointer=memory\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\":\"1\"}} #\"recursion_limit\":60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "display(Image(app.get_graph(xray=1).draw_mermaid_png(\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model.stream(input=\"aaa\", max_completion_tokens=500,\n",
    "#                                        temperature=0):\n",
    "    \n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle_trivial_question():  0.9582333564758301  seconds\n",
      "answer_trivial_question():  0.5984888076782227  seconds\n"
     ]
    }
   ],
   "source": [
    "a = app.invoke(input={\"question\":\"how are you\", \"news_summary\":\"example\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'streaming_avaiable': True,\n",
       " 'response_stream': <generator object BaseChatModel.stream at 0x0000021186F52150>}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sst import transcribe_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = transcribe_audio(\"narrative.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ready to know what happened this week? Let's dive in. First up, fitness enthusiasts are buzzing about high-intensity interval training, which promises to keep you burning calories long after your workout ends. Meanwhile, in the world of international affairs, Ukraine made headlines by using a naval drone to take down a Russian helicopter, marking a significant moment in their ongoing conflict. As Asia celebrated the arrival of 2025 with spectacular fireworks, Elon Musk stirred controversy in Germany by endorsing a far-right party, leading to a media shake-up. Across the Atlantic, Donald Trump surprised many by supporting Elon Musk and the H-1B visa program, causing ripples within the Republican Party. In entertainment, Lily-Rose Depp is making waves with her role in the new Nasratu film, while Trump mourns the loss of former U.S. President Jimmy Carter, who passed away at 100, leaving behind a legacy of peace and humanitarian work. Spain is facing unrest as public employees deal with frozen salaries and healthcare disruptions, while in Brazil, a tragic poisoning incident involving a Christmas cake is under investigation. Azerbaijan and Russia are at odds over a plane crash, with calls for an independent probe. In South Korea, a devastating plane crash claimed 179 lives, marking the worst air disaster in the country in decades. New York is reeling from a scandal involving prison brutality, prompting calls for justice and reform. The WHO's Tedros Adhanom Ghebreyesus narrowly escaped a bombing in Yemen, highlighting the ongoing conflict in the region. Tensions are also high between Venezuela and Argentina over accusations of terrorism, while Ukraine continues to fend off Russian aerial attacks. In Madrid, a graffiti artist faces a hefty fine for his street art spree, and in New York, a shocking video of prison violence has sparked outrage and investigations. Meanwhile, Russia's use of a ghost freight to bypass sanctions is raising alarms in the Baltic region. In China, a tragic incident involving a driver plowing into a crowd has sparked discussions on public mourning and censorship. Back in New York, the Guardian Angels are back on patrol in the subway after a horrific attack, aiming to boost public safety. Finally, Spain's Muface is in turmoil as major health insurers withdraw, leaving many civil servants without private coverage. As the year wraps up, these events remind us of the complexities and challenges facing our world today. Stay tuned for more updates.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle_trivial_question():  1.0071086883544922  seconds\n",
      "retrieve():  0.5809445381164551  secs\n",
      "grade_documents():  1.272484302520752  seconds\n",
      "answer_with_docs():  2.523061990737915  seconds\n",
      "grade_documents_v_questiom():  2.3770363330841064  seconds\n"
     ]
    }
   ],
   "source": [
    "a = app.invoke(input={\"question\":\"que ocurrio en el atentado de nueva orleans\", \"news_summary\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'streaming_avaiable': False,\n",
       " 'response_stream': None,\n",
       " 'generation': AIMessage(content='El atentado en Nueva Orleans ocurriÃ³ el 1 de enero de 2025, cuando un conductor embistiÃ³ a una multitud en Bourbon Street, matando al menos a 15 personas e hiriendo a muchas mÃ¡s. La vÃ­ctima mÃ¡s destacada fue Tiger Bech, un exjugador de fÃºtbol de Princeton, quien sufriÃ³ lesiones internas fatales. Las autoridades estÃ¡n investigando el incidente, que el alcalde de Nueva Orleans ha calificado como un \"ataque terrorista\".', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 5035, 'total_tokens': 5133, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4864}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='last_pred', usage_metadata={'input_tokens': 5035, 'output_tokens': 98, 'total_tokens': 5133, 'input_token_details': {'audio': 0, 'cache_read': 4864}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donald Trump is the 45th President of the United States, having served from January 2017 to January 2021. He was born on June 14, 1946, in Queens, New York, and took over his father\\'s real estate business, renaming it the Trump Organization. Before his presidency, he was known for his reality TV show \"The Apprentice\" and his book \"The Art of the Deal.\" Trump is notable for his unconventional communication style, particularly through social media. He was impeached twice during his presidency and lost reelection to Joe Biden in 2020.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"generation\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle_trivial_question():  0.9483010768890381  seconds\n",
      "retrieve():  1.9162795543670654  secs\n",
      "grade_documents():  1.029559850692749  seconds\n",
      "answer_with_docs():  2.3317995071411133  seconds\n",
      "grade_documents_v_questiom():  2.110718011856079  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'streaming_avaiable': False,\n",
       " 'response_stream': None,\n",
       " 'generation': AIMessage(content='Elon Musk recently called for the UKâ€™s right-wing Reform Party to replace its leader, Nigel Farage, stating that Farage \"doesn\\'t have what it takes.\" This came after Musk criticized the UKâ€™s left-leaning Prime Minister, Keir Starmer.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 2749, 'total_tokens': 2803, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1664}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='last_pred', usage_metadata={'input_tokens': 2749, 'output_tokens': 54, 'total_tokens': 2803, 'input_token_details': {'audio': 0, 'cache_read': 1664}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"what did elon musk say about UK right wing party?\", \"news_summary\":text}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['streaming_avaiable', 'response_stream', 'generation'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverallState(TypedDict):\n",
    "    #includes all the keys of both input and output, + any other intermediate\n",
    "    a:int\n",
    "    b:int\n",
    "    c:int\n",
    "    ou_mami:str\n",
    "    \n",
    "\n",
    "class GGInput(TypedDict):\n",
    "    a : int\n",
    "    b : int\n",
    "    \n",
    "class GGOutput(TypedDict):\n",
    "    c:int\n",
    "    # b : int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wowo = StateGraph(OverallState, input=GGInput, output=GGOutput)\n",
    "# Define the nodes\n",
    "\n",
    "def multiply_node(state): #since its the entrypoint node, it should be state:GGInput\n",
    "    \n",
    "    a = state[\"a\"]\n",
    "    b = state[\"b\"]\n",
    "    \n",
    "    return {\"c\":a*b}\n",
    "wowo.add_node(\"multiply_a_with_b\", multiply_node)\n",
    "# workflow.add_node(\"answer_trivial_question\", answer_trivial_question) \n",
    "# workflow.add_node(\"retrieve\", retrieve) \n",
    "\n",
    "wowo.set_entry_point('multiply_a_with_b')\n",
    "wowo.add_edge('multiply_a_with_b', END)\n",
    "\n",
    "riri = wowo.compile()\n",
    "# workflow.add_node(\"generate_queries\", generate_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 10}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "riri.invoke({\"a\":5, \"b\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| color| of| the| sky| can| vary| depending| on| several| factors|,| including| the| time| of| day|,| weather| conditions|,| and| atmospheric| particles|.| During| a| clear| day|,| the| sky| typically| appears| blue| due| to| the| scattering| of| sunlight| by| the| Earth's| atmosphere|.| This| phenomenon| is| known| as| Ray|leigh| scattering|.| At| sunrise| and| sunset|,| the| sky| can| display| a| range| of| colors|,| including| orange|,| pink|,| and| red|,| due| to| the| angle| of| the| sun| and| the| increased| distance| the| light| travels| through| the| atmosphere|.| On| cloudy| or| over|cast| days|,| the| sky| may| appear| gray|.| Additionally|,| pollution|,| dust|,| and| other| particles| can| also| affect| the| sky|'s| color|.||"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for chunk in model.stream(\"what color is the sky?\", max_completion_tokens=500,\n",
    "                          temperature=0):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=' color', additional_kwargs={}, response_metadata={}, id='run-03dbc03f-03db-441e-9ad3-6e68c5e86f8b')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'streamed_tts_langchain' from 'tts_variants' (c:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\agent\\my-app\\app\\article-prep-agent\\v2\\implementations\\local_audio_chat_demo\\tts_variants.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtts_variants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m streamed_tts_langchain\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'streamed_tts_langchain' from 'tts_variants' (c:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\agent\\my-app\\app\\article-prep-agent\\v2\\implementations\\local_audio_chat_demo\\tts_variants.py)"
     ]
    }
   ],
   "source": [
    "from tts_variants import streamed_tts_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queued sentence: One interesting curiosity about Americans is their love for fast food.\n",
      "Queued sentence: The United States is home to some of the largest and most recognizable fast-food chains in the world, such as McDonald's, Burger King, and Taco Bell.\n",
      "Queued sentence: The fast-food industry has become a significant part of American culture, with many people enjoying the convenience and affordability it offers.\n",
      "Queued sentence: In fact, it's estimated that Americans consume around 50 billion burgers each year!\n",
      "Queued sentence: This phenomenon reflects not only dietary habits but also broader trends in lifestyle and consumer culture in the U.\n",
      "Queued sentence: S.\n",
      "Time taken to start playing audio clip: 2.6088027954101562 seconds\n",
      "Time taken to start playing audio clip: 6.806114673614502 seconds\n",
      "Time taken to start playing audio clip: 15.923211574554443 seconds\n",
      "Time taken to start playing audio clip: 24.633734464645386 seconds\n",
      "Time taken to start playing audio clip: 30.25316071510315 seconds\n",
      "Time taken to start playing audio clip: 37.63345408439636 seconds\n"
     ]
    }
   ],
   "source": [
    "streamed_tts_langchain(model,\n",
    "                       text=\"tell me a curiosity about americans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sst import transcribe_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = transcribe_audio(\"narrative.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"que ocurrio en el atentado de nueva orleans?\", \"news_summary\":text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle_trivial_question():  1.2733216285705566  seconds\n",
      "retrieve():  0.9772970676422119  secs\n",
      "grade_documents():  1.1743078231811523  seconds\n",
      "already searched queries (if applicable): None\n",
      "Elapsed time generate_queries():  2.506319046020508  seconds\n",
      "gonna generate 1 queries\n",
      "Warning: No raw_content found for source https://www.newsweek.com/new-orleans-attack-update-fbi-reveals-new-timeline-events-2009961\n",
      "[*] Elapsed time for search:  3.6064083576202393\n",
      "answer_with_docs():  2.552968978881836  seconds\n",
      "grade_documents_v_questiom():  2.28853702545166  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generation': AIMessage(content='En el atentado de Nueva Orleans, que ocurriÃ³ el DÃ­a de AÃ±o Nuevo, 14 vÃ­ctimas perdieron la vida. El FBI ha proporcionado una actualizaciÃ³n detallada sobre los eventos relacionados con este ataque en Bourbon Street.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 896, 'total_tokens': 940, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='last_pred', usage_metadata={'input_tokens': 896, 'output_tokens': 44, 'total_tokens': 940, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(input=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "'Finished running: detect_if_final_pred:'\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "# for output in app.stream(inputs, thread):\n",
    "#     for key, value in output.items():\n",
    "#         pprint(f\"Finished running: {key}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "'Finished running: detect_if_final_pred:'\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"what did elon musk say about UK right wing party?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generation': AIMessage(content='Elon Musk recently called for the UKâ€™s right-wing Reform Party to replace its leader, Nigel Farage, stating that \"Farage doesnâ€™t have what it takes.\" This came after Musk criticized the UKâ€™s left-leaning Prime Minister, Keir Starmer.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 6014, 'total_tokens': 6069, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5888}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='last_pred', usage_metadata={'input_tokens': 6014, 'output_tokens': 55, 'total_tokens': 6069, 'input_token_details': {'audio': 0, 'cache_read': 5888}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who has accused to who between Venezuela and Argentina?\", \"news_summary\":text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle_trivial_question():  1.068077802658081  seconds\n",
      "retrieve():  0.558140754699707  secs\n",
      "grade_documents():  0.9966485500335693  seconds\n",
      "answer_with_docs():  1.5584099292755127  seconds\n",
      "grade_documents_v_questiom():  2.177999973297119  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generation': AIMessage(content='Venezuela has accused an Argentine officer of terrorism, which has contributed to the deteriorating relations between the two countries.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 1618, 'total_tokens': 1643, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='last_pred', usage_metadata={'input_tokens': 1618, 'output_tokens': 25, 'total_tokens': 1643, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"which is the current political party at germanu?\", \"news_summary\":text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle_trivial_question():  0.9733643531799316  seconds\n",
      "retrieve():  0.6992456912994385  secs\n",
      "grade_documents():  0.9832816123962402  seconds\n",
      "already searched queries (if applicable): None\n",
      "Elapsed time generate_queries():  1.618110179901123  seconds\n",
      "gonna generate 1 queries\n",
      "Warning: No raw_content found for source https://politpro.eu/en/germany\n",
      "[*] Elapsed time for search:  2.277712345123291\n",
      "answer_with_docs():  1.450340986251831  seconds\n",
      "grade_documents_v_questiom():  2.016035795211792  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generation': AIMessage(content='The current political party in Germany is the SPD, led by Chancellor Olaf Scholz, who is running for re-election in the upcoming 2025 federal election.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 907, 'total_tokens': 940, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='last_pred', usage_metadata={'input_tokens': 907, 'output_tokens': 33, 'total_tokens': 940, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"when did elon musk come to the U.S?\", \"news_summary\":text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle_trivial_question():  0.9079451560974121  seconds\n",
      "retrieve():  1.0117716789245605  secs\n",
      "grade_documents():  1.0382065773010254  seconds\n",
      "already searched queries (if applicable): None\n",
      "Elapsed time generate_queries():  1.7156682014465332  seconds\n",
      "gonna generate 2 queries\n",
      "Warning: No raw_content found for source https://www.newsweek.com/elon-musk-immigration-status-1990s-donald-trump-twitter-2024-election-1978588\n",
      "Warning: No raw_content found for source https://www.cnbc.com/2020/05/26/elon-musk-on-his-success-america-is-the-land-of-opportunity.html\n",
      "[*] Elapsed time for search:  4.6060967445373535\n",
      "answer_with_docs():  1.2704432010650635  seconds\n",
      "grade_documents_v_questiom():  2.0480756759643555  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generation': AIMessage(content='Elon Musk moved to the U.S. in 1992.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 1140, 'total_tokens': 1155, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='last_pred', usage_metadata={'input_tokens': 1140, 'output_tokens': 15, 'total_tokens': 1155, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sample event \n",
    "\n",
    "```python\n",
    "\n",
    "{'event': 'on_chain_end',\n",
    "\n",
    " 'data': {'output': \n",
    " \n",
    "  {'news_summary': \"Ready to know ,\n",
    "   'question': 'who is the nephew of Francisco Hitler?',\n",
    "   'question_type': 'is_trivial',\n",
    "   'generation': \"There is no widely recognized historical figure named Francisco Hitler, and Adolf Hitler, the infamous leader of Nazi Germany, did not have a nephew by that name. Adolf Hitler did have a nephew named William Patrick Hitler, who was the son of Adolf's half-brother, Alois Hitler Jr. If you meant a different person or context, please provide more details.\",\n",
    "   'iterations': 0}},\n",
    "\n",
    " 'run_id': 'b2236655-5928-4feb-8926-a65ea904b123',\n",
    " 'name': 'LangGraph',\n",
    " 'tags': [],\n",
    " 'metadata': {},\n",
    " 'parent_ids': []}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'event': 'on_chat_model_stream',\n",
    " 'data': {'chunk':\n",
    "     AIMessageChunk(content=' widely', \n",
    "                    additional_kwargs={}, response_metadata={},\n",
    "                    id='run-bde93253-82d3-42a1-8584-88f0abd5ee8a')},\n",
    " \n",
    " 'run_id': 'bde93253-82d3-42a1-8584-88f0abd5ee8a', 'name': 'ChatOpenAI',\n",
    " 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 2, \n",
    "                                      'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:56ca808a-954c-1893-fb4d-3b16d1da3ac2', 'checkpoint_ns': 'answer_trivial_question:56ca808a-954c-1893-fb4d-3b16d1da3ac2', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'parent_ids': ['464e03d0-68ee-45ba-b9db-c65c36fadd5a']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event': 'on_chain_end',\n",
       " 'data': {'output': {'news_summary': \"Ready to know what happened this week? Let's dive in. First up, fitness enthusiasts are buzzing about high-intensity interval training, which promises to keep you burning calories long after your workout ends. Meanwhile, in the world of international affairs, Ukraine made headlines by using a naval drone to take down a Russian helicopter, marking a significant moment in their ongoing conflict. As Asia celebrated the arrival of 2025 with spectacular fireworks, Elon Musk stirred controversy in Germany by endorsing a far-right party, leading to a media shake-up. Across the Atlantic, Donald Trump surprised many by supporting Elon Musk and the H-1B visa program, causing ripples within the Republican Party. In entertainment, Lily-Rose Depp is making waves with her role in the new Nasratu film, while Trump mourns the loss of former U.S. President Jimmy Carter, who passed away at 100, leaving behind a legacy of peace and humanitarian work. Spain is facing unrest as public employees deal with frozen salaries and healthcare disruptions, while in Brazil, a tragic poisoning incident involving a Christmas cake is under investigation. Azerbaijan and Russia are at odds over a plane crash, with calls for an independent probe. In South Korea, a devastating plane crash claimed 179 lives, marking the worst air disaster in the country in decades. New York is reeling from a scandal involving prison brutality, prompting calls for justice and reform. The WHO's Tedros Adhanom Ghebreyesus narrowly escaped a bombing in Yemen, highlighting the ongoing conflict in the region. Tensions are also high between Venezuela and Argentina over accusations of terrorism, while Ukraine continues to fend off Russian aerial attacks. In Madrid, a graffiti artist faces a hefty fine for his street art spree, and in New York, a shocking video of prison violence has sparked outrage and investigations. Meanwhile, Russia's use of a ghost freight to bypass sanctions is raising alarms in the Baltic region. In China, a tragic incident involving a driver plowing into a crowd has sparked discussions on public mourning and censorship. Back in New York, the Guardian Angels are back on patrol in the subway after a horrific attack, aiming to boost public safety. Finally, Spain's Muface is in turmoil as major health insurers withdraw, leaving many civil servants without private coverage. As the year wraps up, these events remind us of the complexities and challenges facing our world today. Stay tuned for more updates.\\n\",\n",
       "   'question': 'who is the nephew of Francisco Hitler?',\n",
       "   'question_type': 'is_trivial',\n",
       "   'generation': \"There is no widely recognized historical figure named Francisco Hitler, and Adolf Hitler, the infamous leader of Nazi Germany, did not have a nephew by that name. Adolf Hitler did have a nephew named William Patrick Hitler, who was the son of Adolf's half-brother, Alois Hitler Jr. If you meant a different person or context, please provide more details.\",\n",
       "   'iterations': 0}},\n",
       " 'run_id': 'b2236655-5928-4feb-8926-a65ea904b123',\n",
       " 'name': 'LangGraph',\n",
       " 'tags': [],\n",
       " 'metadata': {},\n",
       " 'parent_ids': []}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample event \n",
    "\n",
    "```python\n",
    "\n",
    "{'event': 'on_chain_end',\n",
    "\n",
    " 'data': {'output': \n",
    " \n",
    "  {'news_summary': \"Ready to know ,\n",
    "   'question': 'who is the nephew of Francisco Hitler?',\n",
    "   'question_type': 'is_trivial',\n",
    "   'generation': \"There is no widely recognized historical figure named Francisco Hitler, and Adolf Hitler, the infamous leader of Nazi Germany, did not have a nephew by that name. Adolf Hitler did have a nephew named William Patrick Hitler, who was the son of Adolf's half-brother, Alois Hitler Jr. If you meant a different person or context, please provide more details.\",\n",
    "   'iterations': 0}},\n",
    "\n",
    " 'run_id': 'b2236655-5928-4feb-8926-a65ea904b123',\n",
    " 'name': 'LangGraph',\n",
    " 'tags': [],\n",
    " 'metadata': {},\n",
    " 'parent_ids': []}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah\n"
     ]
    }
   ],
   "source": [
    "if \".\":\n",
    "    \n",
    "    print(\"yeah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = llm.with_config({\"run_name\": \"my_parser\"}).invoke(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', 'Hello! How can I assist you today?')\n",
      "('additional_kwargs', {'refusal': None})\n",
      "('response_metadata', {'token_usage': {'completion_tokens': 10, 'prompt_tokens': 9, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_5f20662549', 'finish_reason': 'stop', 'logprobs': None})\n",
      "('type', 'ai')\n",
      "('name', None)\n",
      "('id', 'run-a1939b84-6d78-4ebd-a407-a2631df1b658-0')\n",
      "('example', False)\n",
      "('tool_calls', [])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', {'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "for i in a :\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah\n"
     ]
    }
   ],
   "source": [
    "if event[\"data\"][\"output\"][\"generation\"]:\n",
    "    \n",
    "    print(\"yeah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_chat_model_stream {'chunk': AIMessageChunk(content='There', additional_kwargs={}, response_metadata={}, id='run-dd8f1b16-7f3f-4221-a3c6-8f132d8da2e9')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " infamous|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'cca32238-5f3a-40b0-8128-d194ad37d8bb', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:50c9ff04-674b-a566-d720-45f3514f74b4', 'checkpoint_ns': 'answer_trivial_question:50c9ff04-674b-a566-d720-45f3514f74b4', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' dictator', additional_kwargs={}, response_metadata={}, id='run-cca32238-5f3a-40b0-8128-d194ad37d8bb')}, 'parent_ids': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event': 'on_chain_end',\n",
       " 'name': 'LangGraph',\n",
       " 'run_id': 'e9c51a5c-6f04-4fa5-9e88-4c0a2d05359d',\n",
       " 'tags': [],\n",
       " 'metadata': {'thread_id': '4'},\n",
       " 'data': {'output': [{'handle_trivial_question': {'question': 'who is the nephew of Francisco Hitler?',\n",
       "     'question_type': 'is_trivial',\n",
       "     'iterations': 0}},\n",
       "   {'answer_trivial_question': {'question': 'who is the nephew of Francisco Hitler?',\n",
       "     'generation': \"There is no widely known or documented individual named Francisco Hitler, and therefore, no information about a nephew of such a person. It's possible that there might be some confusion or misinformation regarding the name. If you meant a different historical figure or need information on someone else, please provide more context or details.\"}}]},\n",
       " 'parent_ids': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "There|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'aab2fcad-b3c7-4b2a-a152-b716e96fd238', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'handle_trivial_question', 'langgraph_triggers': ['start:handle_trivial_question'], 'langgraph_path': ('__pregel_pull', 'handle_trivial_question'), 'langgraph_checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-aab2fcad-b3c7-4b2a-a152-b716e96fd238')}, 'parent_ids': []}\n",
      "|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'aab2fcad-b3c7-4b2a-a152-b716e96fd238', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'handle_trivial_question', 'langgraph_triggers': ['start:handle_trivial_question'], 'langgraph_path': ('__pregel_pull', 'handle_trivial_question'), 'langgraph_checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='is', additional_kwargs={}, response_metadata={}, id='run-aab2fcad-b3c7-4b2a-a152-b716e96fd238')}, 'parent_ids': []}\n",
      "is|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'aab2fcad-b3c7-4b2a-a152-b716e96fd238', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'handle_trivial_question', 'langgraph_triggers': ['start:handle_trivial_question'], 'langgraph_path': ('__pregel_pull', 'handle_trivial_question'), 'langgraph_checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='_tr', additional_kwargs={}, response_metadata={}, id='run-aab2fcad-b3c7-4b2a-a152-b716e96fd238')}, 'parent_ids': []}\n",
      "_tr|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'aab2fcad-b3c7-4b2a-a152-b716e96fd238', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'handle_trivial_question', 'langgraph_triggers': ['start:handle_trivial_question'], 'langgraph_path': ('__pregel_pull', 'handle_trivial_question'), 'langgraph_checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='ivial', additional_kwargs={}, response_metadata={}, id='run-aab2fcad-b3c7-4b2a-a152-b716e96fd238')}, 'parent_ids': []}\n",
      "ivial|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'aab2fcad-b3c7-4b2a-a152-b716e96fd238', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 1, 'langgraph_node': 'handle_trivial_question', 'langgraph_triggers': ['start:handle_trivial_question'], 'langgraph_path': ('__pregel_pull', 'handle_trivial_question'), 'langgraph_checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'checkpoint_ns': 'handle_trivial_question:5a1a78e0-afd3-a273-492f-e4dfce223d10', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782'}, id='run-aab2fcad-b3c7-4b2a-a152-b716e96fd238')}, 'parent_ids': []}\n",
      "|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      "|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='There', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      "There|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " is|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' no', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " no|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' widely', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " widely|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " known|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " or|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' documented', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " documented|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' individual', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " individual|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' named', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " named|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " Francisco|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' Hitler', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " Hitler|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      ",|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " and|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' therefore', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " therefore|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      ",|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' no', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " no|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' information', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " information|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " about|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " a|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' nephew', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " nephew|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " of|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' such', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " such|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " a|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' person', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " person|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      ".|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=\" It's\", additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " It's|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' possible', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " possible|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " that|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' there', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " there|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' might', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " might|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " be|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " some|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' confusion', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " confusion|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " or|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' misinformation', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " misinformation|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' regarding', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " regarding|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " the|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' name', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " name|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      ".|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' If', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " If|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " you|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' meant', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " meant|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " a|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' different', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " different|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' historical', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " historical|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' figure', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " figure|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " or|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' need', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " need|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' information', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " information|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " on|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' someone', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " someone|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' else', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " else|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      ",|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' please', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " please|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' provide', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " provide|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' more', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " more|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' context', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " context|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " or|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content=' details', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      " details|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      ".|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782'}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n",
      "|"
     ]
    }
   ],
   "source": [
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in app.astream_events(inputs, thread, version=\"v1\"\n",
    "                                      ):\n",
    "    kind = event[\"event\"]\n",
    "    \n",
    "    \n",
    "    #we retrieve the events when the llm is otuputting text\n",
    "    #and then we start showing token by token async\n",
    "    \n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        \n",
    "        # print(event[\"metadata\"][\"langgraph_node\"])\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content and event[\"metadata\"][\"langgraph_node\"] == \"generation\" or \"answer_trivial_question\":\n",
    "            print(event)\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".|{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '9400c73b-de96-4212-b8de-b794fb1a5e1b', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '4', 'langgraph_step': 2, 'langgraph_node': 'answer_trivial_question', 'langgraph_triggers': ['branch:handle_trivial_question:detect_trivial_question:answer_trivial_question'], 'langgraph_path': ('__pregel_pull', 'answer_trivial_question'), 'langgraph_checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'checkpoint_ns': 'answer_trivial_question:2c8e6955-2750-bdc7-8c46-2f5bc1f29843', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_method': 'traceable'}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782'}, id='run-9400c73b-de96-4212-b8de-b794fb1a5e1b')}, 'parent_ids': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = llm.with_config({\"run_name\": \"model\"}).invoke(\"hii my dog!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.id = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = {\"messages\": [HumanMessage(content=\"what's the weather in nyc?\")]}\n",
    "\n",
    "\n",
    "async for event in app.astream_events(inputs, version=\"v2\")\n",
    "                                    #   include_names=[\"my_parser\"]):\n",
    "    \n",
    "    #todo: if we gave to the llm an unique way to identify it in the events with llm with_config({\"run_name\": \"my_parser\"})\n",
    "    \n",
    "    # kind = event[\"event\"]\n",
    "    # tags = event.get(\"tags\", [])\n",
    "    # # filter on the custom tag\n",
    "    \n",
    "    \n",
    "    # events.append(event)\n",
    "    # print(kind, event[\"data\"])\n",
    "    # if kind == \"on_chat_model_stream\":\n",
    "    #     data = event[\"data\"]\n",
    "    #     output_json = data.get(\"output\", None)\n",
    "        \n",
    "    #     if output_json != None:\n",
    "            \n",
    "    #         generation = event.get(\"generation\", None)\n",
    "            \n",
    "            \n",
    "    #         if generation is not None:\n",
    "            \n",
    "        \n",
    "    #     # if data[\"chunk\"].content:\n",
    "    #     #     # Empty content in the context of OpenAI or Anthropic usually means\n",
    "    #     #     # that the model is asking for a tool to be invoked.\n",
    "    #     #     # So we only print non-empty content\n",
    "    #             print(data[\"chunk\"].content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_summary': \"Ready to know what happened this week? Let's dive in. First up, fitness enthusiasts are buzzing about high-intensity interval training, which promises to keep you burning calories long after your workout ends. Meanwhile, in the world of international affairs, Ukraine made headlines by using a naval drone to take down a Russian helicopter, marking a significant moment in their ongoing conflict. As Asia celebrated the arrival of 2025 with spectacular fireworks, Elon Musk stirred controversy in Germany by endorsing a far-right party, leading to a media shake-up. Across the Atlantic, Donald Trump surprised many by supporting Elon Musk and the H-1B visa program, causing ripples within the Republican Party. In entertainment, Lily-Rose Depp is making waves with her role in the new Nasratu film, while Trump mourns the loss of former U.S. President Jimmy Carter, who passed away at 100, leaving behind a legacy of peace and humanitarian work. Spain is facing unrest as public employees deal with frozen salaries and healthcare disruptions, while in Brazil, a tragic poisoning incident involving a Christmas cake is under investigation. Azerbaijan and Russia are at odds over a plane crash, with calls for an independent probe. In South Korea, a devastating plane crash claimed 179 lives, marking the worst air disaster in the country in decades. New York is reeling from a scandal involving prison brutality, prompting calls for justice and reform. The WHO's Tedros Adhanom Ghebreyesus narrowly escaped a bombing in Yemen, highlighting the ongoing conflict in the region. Tensions are also high between Venezuela and Argentina over accusations of terrorism, while Ukraine continues to fend off Russian aerial attacks. In Madrid, a graffiti artist faces a hefty fine for his street art spree, and in New York, a shocking video of prison violence has sparked outrage and investigations. Meanwhile, Russia's use of a ghost freight to bypass sanctions is raising alarms in the Baltic region. In China, a tragic incident involving a driver plowing into a crowd has sparked discussions on public mourning and censorship. Back in New York, the Guardian Angels are back on patrol in the subway after a horrific attack, aiming to boost public safety. Finally, Spain's Muface is in turmoil as major health insurers withdraw, leaving many civil servants without private coverage. As the year wraps up, these events remind us of the complexities and challenges facing our world today. Stay tuned for more updates.\\n\", 'question': 'who is the nephew of Francisco Hitler?'}\n",
      "{'news_summary': \"Ready to know what happened this week? Let's dive in. First up, fitness enthusiasts are buzzing about high-intensity interval training, which promises to keep you burning calories long after your workout ends. Meanwhile, in the world of international affairs, Ukraine made headlines by using a naval drone to take down a Russian helicopter, marking a significant moment in their ongoing conflict. As Asia celebrated the arrival of 2025 with spectacular fireworks, Elon Musk stirred controversy in Germany by endorsing a far-right party, leading to a media shake-up. Across the Atlantic, Donald Trump surprised many by supporting Elon Musk and the H-1B visa program, causing ripples within the Republican Party. In entertainment, Lily-Rose Depp is making waves with her role in the new Nasratu film, while Trump mourns the loss of former U.S. President Jimmy Carter, who passed away at 100, leaving behind a legacy of peace and humanitarian work. Spain is facing unrest as public employees deal with frozen salaries and healthcare disruptions, while in Brazil, a tragic poisoning incident involving a Christmas cake is under investigation. Azerbaijan and Russia are at odds over a plane crash, with calls for an independent probe. In South Korea, a devastating plane crash claimed 179 lives, marking the worst air disaster in the country in decades. New York is reeling from a scandal involving prison brutality, prompting calls for justice and reform. The WHO's Tedros Adhanom Ghebreyesus narrowly escaped a bombing in Yemen, highlighting the ongoing conflict in the region. Tensions are also high between Venezuela and Argentina over accusations of terrorism, while Ukraine continues to fend off Russian aerial attacks. In Madrid, a graffiti artist faces a hefty fine for his street art spree, and in New York, a shocking video of prison violence has sparked outrage and investigations. Meanwhile, Russia's use of a ghost freight to bypass sanctions is raising alarms in the Baltic region. In China, a tragic incident involving a driver plowing into a crowd has sparked discussions on public mourning and censorship. Back in New York, the Guardian Angels are back on patrol in the subway after a horrific attack, aiming to boost public safety. Finally, Spain's Muface is in turmoil as major health insurers withdraw, leaving many civil servants without private coverage. As the year wraps up, these events remind us of the complexities and challenges facing our world today. Stay tuned for more updates.\\n\", 'question': 'who is the nephew of Francisco Hitler?', 'question_type': 'is_trivial', 'iterations': 0}\n",
      "{'news_summary': \"Ready to know what happened this week? Let's dive in. First up, fitness enthusiasts are buzzing about high-intensity interval training, which promises to keep you burning calories long after your workout ends. Meanwhile, in the world of international affairs, Ukraine made headlines by using a naval drone to take down a Russian helicopter, marking a significant moment in their ongoing conflict. As Asia celebrated the arrival of 2025 with spectacular fireworks, Elon Musk stirred controversy in Germany by endorsing a far-right party, leading to a media shake-up. Across the Atlantic, Donald Trump surprised many by supporting Elon Musk and the H-1B visa program, causing ripples within the Republican Party. In entertainment, Lily-Rose Depp is making waves with her role in the new Nasratu film, while Trump mourns the loss of former U.S. President Jimmy Carter, who passed away at 100, leaving behind a legacy of peace and humanitarian work. Spain is facing unrest as public employees deal with frozen salaries and healthcare disruptions, while in Brazil, a tragic poisoning incident involving a Christmas cake is under investigation. Azerbaijan and Russia are at odds over a plane crash, with calls for an independent probe. In South Korea, a devastating plane crash claimed 179 lives, marking the worst air disaster in the country in decades. New York is reeling from a scandal involving prison brutality, prompting calls for justice and reform. The WHO's Tedros Adhanom Ghebreyesus narrowly escaped a bombing in Yemen, highlighting the ongoing conflict in the region. Tensions are also high between Venezuela and Argentina over accusations of terrorism, while Ukraine continues to fend off Russian aerial attacks. In Madrid, a graffiti artist faces a hefty fine for his street art spree, and in New York, a shocking video of prison violence has sparked outrage and investigations. Meanwhile, Russia's use of a ghost freight to bypass sanctions is raising alarms in the Baltic region. In China, a tragic incident involving a driver plowing into a crowd has sparked discussions on public mourning and censorship. Back in New York, the Guardian Angels are back on patrol in the subway after a horrific attack, aiming to boost public safety. Finally, Spain's Muface is in turmoil as major health insurers withdraw, leaving many civil servants without private coverage. As the year wraps up, these events remind us of the complexities and challenges facing our world today. Stay tuned for more updates.\\n\", 'question': 'who is the nephew of Francisco Hitler?', 'question_type': 'is_trivial', 'generation': 'There is no widely recognized historical figure named Francisco Hitler, and Adolf Hitler, the infamous dictator of Nazi Germany, did not have any known relatives named Francisco. If you meant a different person or if this is a fictional or hypothetical scenario, please provide more context or clarify your question.', 'iterations': 0}\n"
     ]
    }
   ],
   "source": [
    "first = True\n",
    "async for event in app.astream(inputs, config=thread, stream_mode=\"values\"):\n",
    "    # if msg.content and not isinstance(msg, HumanMessage):\n",
    "    #     print(msg.content, end=\"|\", flush=True)\n",
    "\n",
    "    # if isinstance(msg, AIMessageChunk):\n",
    "    #     if first:\n",
    "    #         gathered = msg\n",
    "    #         first = False\n",
    "    #     else:\n",
    "    #         gathered = gathered + msg\n",
    "\n",
    "    #     if msg.tool_call_chunks:\n",
    "    #         print(gathered.tool_calls)\n",
    "    \n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: 'is'\n",
      "Chat model chunk: '_tr'\n",
      "Chat model chunk: 'ivial'\n",
      "Chat model chunk: ''\n",
      "Chat model chunk: ''\n",
      "Chat model chunk: 'There'\n",
      "Chat model chunk: ' is'\n",
      "Chat model chunk: ' no'\n",
      "Chat model chunk: ' widely'\n",
      "Chat model chunk: ' recognized'\n",
      "Chat model chunk: ' historical'\n",
      "Chat model chunk: ' figure'\n",
      "Chat model chunk: ' named'\n",
      "Chat model chunk: ' Francisco'\n",
      "Chat model chunk: ' Hitler'\n",
      "...\n",
      "Final response: is_trivialThere is no widely recognized historical figure named Francisco Hitler\n"
     ]
    }
   ],
   "source": [
    "num_events = 0\n",
    "response_buffer = []\n",
    "\n",
    "async for event in app.astream_events(inputs, version=\"v2\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        chunk_content = event['data']['chunk'].content\n",
    "        if chunk_content.strip():  # Ignore empty chunks\n",
    "            response_buffer.append(chunk_content)\n",
    "        print(f\"Chat model chunk: {repr(chunk_content)}\", flush=True)\n",
    "    \n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "    \n",
    "    num_events += 1\n",
    "    if num_events > 30:\n",
    "        # Truncate the output after 30 events\n",
    "        print(\"...\")\n",
    "        break\n",
    "\n",
    "# After the loop, print the final accumulated response\n",
    "final_response = ''.join(response_buffer)\n",
    "print(\"Final response:\", final_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_chain_start: LangGraph\n",
      "on_chain_start: __start__\n",
      "on_chain_end: __start__\n",
      "on_chain_start: handle_trivial_question\n",
      "on_chat_model_start: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_end: ChatOpenAI\n",
      "on_chain_start: _write\n",
      "on_chain_end: _write\n",
      "on_chain_start: detect_trivial_question\n",
      "on_chain_end: detect_trivial_question\n",
      "on_chain_stream: handle_trivial_question\n",
      "on_chain_end: handle_trivial_question\n",
      "on_chain_stream: LangGraph\n",
      "on_chain_start: answer_trivial_question\n",
      "on_chat_model_start: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_stream: ChatOpenAI\n",
      "on_chat_model_end: ChatOpenAI\n",
      "on_chain_start: _write\n",
      "on_chain_end: _write\n",
      "on_chain_stream: answer_trivial_question\n",
      "on_chain_end: answer_trivial_question\n",
      "on_chain_stream: LangGraph\n",
      "on_chain_end: LangGraph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = {\"question\": \"who is the nephew of Francisco Hitler?\", \"news_summary\":text}\n",
    "\n",
    "async for event in app.astream_events(inputs, config=thread,version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    print(f\"{kind}: {event['name']}\")\n",
    "    \n",
    "    # if kind == \"on_chat_model_stream\" and event[\"name\"] == \"LangGraph\":\n",
    "    #     content = event[\"data\"][\"chunk\"].content\n",
    "    #     if content:\n",
    "    #         print(\"a\")\n",
    "    #         # Empty content in the context of OpenAI means\n",
    "    #         # that the model is asking for a tool to be invoked.\n",
    "    #         # So we only print non-empty content\n",
    "    #         print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = transcribe_audio(\"narrative.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already searched queries (if applicable): None\n",
      "gonna generate 1 queries\n"
     ]
    }
   ],
   "source": [
    "res = app.invoke({\"question\":\"capital of Spain\", \"news_summary\":text}, thread)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', 'The capital of Spain is Madrid.')\n",
      "('additional_kwargs', {'refusal': None})\n",
      "('response_metadata', {'token_usage': {'completion_tokens': 8, 'prompt_tokens': 1811, 'total_tokens': 1819, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1536}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None})\n",
      "('type', 'ai')\n",
      "('name', None)\n",
      "('id', 'last_pred')\n",
      "('example', False)\n",
      "('tool_calls', [])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', {'input_tokens': 1811, 'output_tokens': 8, 'total_tokens': 1819, 'input_token_details': {'audio': 0, 'cache_read': 1536}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    \n",
    "    print(i) #it indeed have the .id = last_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ready to know what happened this week? Let's dive in. First up, fitness enthusiasts are buzzing about high-intensity interval training, which promises to keep you burning calories long after your workout ends. Meanwhile, in the world of international affairs, Ukraine made headlines by using a naval drone to take down a Russian helicopter, marking a significant moment in their ongoing conflict. As Asia celebrated the arrival of 2025 with spectacular fireworks, Elon Musk stirred controversy in Germany by endorsing a far-right party, leading to a media shake-up. Across the Atlantic, Donald Trump surprised many by supporting Elon Musk and the H-1B visa program, causing ripples within the Republican Party. In entertainment, Lily-Rose Depp is making waves with her role in the new Nasratu film, while Trump mourns the loss of former U.S. President Jimmy Carter, who passed away at 100, leaving behind a legacy of peace and humanitarian work. Spain is facing unrest as public employees deal with frozen salaries and healthcare disruptions, while in Brazil, a tragic poisoning incident involving a Christmas cake is under investigation. Azerbaijan and Russia are at odds over a plane crash, with calls for an independent probe. In South Korea, a devastating plane crash claimed 179 lives, marking the worst air disaster in the country in decades. New York is reeling from a scandal involving prison brutality, prompting calls for justice and reform. The WHO's Tedros Adhanom Ghebreyesus narrowly escaped a bombing in Yemen, highlighting the ongoing conflict in the region. Tensions are also high between Venezuela and Argentina over accusations of terrorism, while Ukraine continues to fend off Russian aerial attacks. In Madrid, a graffiti artist faces a hefty fine for his street art spree, and in New York, a shocking video of prison violence has sparked outrage and investigations. Meanwhile, Russia's use of a ghost freight to bypass sanctions is raising alarms in the Baltic region. In China, a tragic incident involving a driver plowing into a crowd has sparked discussions on public mourning and censorship. Back in New York, the Guardian Angels are back on patrol in the subway after a horrific attack, aiming to boost public safety. Finally, Spain's Muface is in turmoil as major health insurers withdraw, leaving many civil servants without private coverage. As the year wraps up, these events remind us of the complexities and challenges facing our world today. Stay tuned for more updates.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already searched queries (if applicable): None\n",
      "gonna generate 1 queries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Pablo! The latest news in AI is that OpenAI is shifting its focus towards \"superintelligence.\" CEO Sam Altman believes they know how to build artificial general intelligence and aims to develop highly autonomous systems that could outperform humans in economically valuable work. This could significantly enhance scientific discovery and innovation. However, he also acknowledges that current AI technology has limitations.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1973, 'total_tokens': 2046, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='last_pred', usage_metadata={'input_tokens': 1973, 'output_tokens': 73, 'total_tokens': 2046, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "app.invoke({\"question\":\"hi, my name is pablo, i want to know the lastest news of ai\", \"news_summary\":text}, thread)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.invoke({\"question\":\"which was my name?\", \"news_summary\":text}, thread)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in a[0]:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from pprint import pprint\n",
    "# # inputs = {\"question\": \"hi, my name is pablo\", \"news_summary\":text}\n",
    "# # for output in app.stream(inputs, thread):\n",
    "# #     for key, value in output.items():\n",
    "# #         pprint(f\"Finished running: {key}:\")\n",
    "# # pprint(value[\"generation\"])\n",
    "\n",
    "# from pprint import pprint\n",
    "# inputs = {\"question\": \"hi, which was my name?\", \"news_summary\":text}\n",
    "# for output in app.stream(inputs, thread):\n",
    "#     for key, value in output.items():\n",
    "#         pprint(f\"Finished running: {key}:\")\n",
    "# pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# inputs = {\"question\": \"tell me the last\", \"news_summary\":text}\n",
    "# for output in app.stream(inputs, thread):\n",
    "#     for key, value in output.items():\n",
    "#         pprint(f\"Finished running: {key}:\")\n",
    "# pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEM #3: Determine how much `n_result` sources do we get for each search query\n",
    "\n",
    "- We should consider those questions which may lead to incoherences or detailed questions, to search for more thrustworthy sources\n",
    "\n",
    "- Decreasing `n_results` will also reduce the latency of the model\n",
    "\n",
    "\n",
    "some values:\n",
    "> With `n_values=1` --> took 7,7 sec for inference\n",
    "\n",
    "> With `n_values=2` --> 12 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decission': 'useful', 'feedback': None, 'iterations': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): None\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 1 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "'The capital of Spain is Madrid.'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"capital of spain\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): n_queries=1 queries=['capital of Spain'] tavily_days=[None] tavily_topic=['general']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 1 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "already searched queries (if applicable): n_queries=1 queries=['current ruling political party in Venezuela 2025'] tavily_days=[7] tavily_topic=['news']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 1 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "forcing stop of the graph...\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "('The current ruling political party in Venezuela is the United Socialist '\n",
      " 'Party of Venezuela (PSUV). NicolÃ¡s Maduro is the leader of this party and '\n",
      " 'has been in power since 2013.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"which is the current political party at Venezuela?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): None\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 2 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "'Finished running: detect_if_final_pred:'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[170], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m         pprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished running: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m pprint(\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeneration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"which is the importance of latency in AI. audio models? \", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): n_queries=3 queries=['importance of latency in AI audio models', 'how latency affects AI audio processing', 'latency in AI audio models explained'] tavily_days=[None, None, None] tavily_topic=['general', 'general', 'general']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 2 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "('Yes, there is a risk of new COVID infections in China, but the current '\n",
      " 'concern is more about a surge in respiratory illnesses, including human '\n",
      " 'metapneumovirus (HMPV). While there is an increase in these infections, '\n",
      " \"China's National Disease Control and Prevention Administration has reported \"\n",
      " 'that the country is safe to visit. The situation is not considered a global '\n",
      " 'health emergency by the World Health Organization, and there is more herd '\n",
      " 'immunity against HMPV compared to a novel virus like COVID-19 at the start '\n",
      " 'of the pandemic.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"Is there is any risk of new COVID infection in China?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): n_queries=2 queries=['current COVID-19 situation in China', 'risk of new COVID-19 variants in China'] tavily_days=[7, 7] tavily_topic=['news', 'news']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 3 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: answer_with_docs:'\n",
      "already searched queries (if applicable): n_queries=3 queries=['COVID-19 spread from China to Europe risk assessment', 'impact of new COVID-19 variants on international travel', 'measures taken by Europe to prevent COVID-19 spread from China'] tavily_days=[7, 7, 7] tavily_topic=['news', 'news', 'news']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 2 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "(\"The context provided doesn't specifically address the risk of new COVID \"\n",
      " 'infections in China reaching Europe. However, it does mention that COVID-19 '\n",
      " 'is still present globally, with ongoing mutations and variants. The World '\n",
      " 'Health Organization (WHO) continues to urge China to share data to better '\n",
      " 'understand the origins and current status of COVID-19. While the virus is '\n",
      " 'less deadly now due to built-up immunity and vaccinations, it is still '\n",
      " 'evolving, which means scientists are closely monitoring it.\\n'\n",
      " '\\n'\n",
      " 'Given this, while there is always a potential risk of new infections '\n",
      " \"spreading internationally, the current context doesn't highlight any \"\n",
      " 'specific new threat from China to Europe. The situation requires ongoing '\n",
      " 'monitoring and cooperation between countries to manage and mitigate risks '\n",
      " 'effectively.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"would it be the risk that new COVID infection in China reaches Europe?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): None\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 1 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "('In Spain, the main left-wing political parties are Podemos and the Spanish '\n",
      " \"Socialist Workers' Party (PSOE). Podemos is known for its left-wing to \"\n",
      " 'far-left stance, while PSOE is a center-left party. Both have been involved '\n",
      " 'in coalition governments, with PSOE currently being part of the ruling '\n",
      " 'coalition alongside Sumar, a new left-wing platform.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"what is the left-wing party in politics in spain\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: answer_trivial_question:'\n",
      "('It seems like there might be some confusion in your question. Francisco '\n",
      " 'Franco and Adolf Hitler were two different historical figures. Francisco '\n",
      " 'Franco was the dictator of Spain from 1939 until his death in 1975. Adolf '\n",
      " 'Hitler was the dictator of Nazi Germany from 1933 to 1945. If you meant to '\n",
      " 'ask about their relationship or any specific aspect of their interactions, '\n",
      " 'feel free to provide more details!')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"which was the name of Franco Hitler\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: we need to handle when questions are not grabbed correctly so it can lead to infinite recursions/iterations for questions like \"I want to know the last\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bug #1: (DONE) Missleading questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): n_queries=3 queries=['importance of latency in AI audio models', 'how latency affects AI audio processing', 'impact of latency on AI-driven audio applications'] tavily_days=[None, None, None] tavily_topic=['general', 'general', 'general']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 3 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "('The question seems to be based on a misunderstanding. The AfD, or '\n",
      " 'Alternative for Germany, is a far-right political party in Germany, and '\n",
      " 'there is no indication that they support the PSOE, which is a '\n",
      " \"social-democratic party in Spain. The context provided discusses Elon Musk's \"\n",
      " 'support for the AfD, but it does not mention any connection or support '\n",
      " 'between the AfD and PSOE. These two parties have very different political '\n",
      " \"ideologies and operate in different countries, so it's unlikely they would \"\n",
      " 'support each other.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "#TODO: sample BUG in the graph\n",
    "#When you ask questions which are missleading or not real, the graph will fall into an infinite loop\n",
    "#this is because once it ensures the returned docs are related to it, it will ensure the question actually responds to the docs\n",
    "#so it won't realize that the question is not real or cohesive hence it won't never get a precisse answer\n",
    "#todo: porque nunca vas a responder de forma precisa a una pregunta errÃ³nea, porque los datos de web/docs no proveeran tal respuesta, sino una respuesta valida\n",
    "\n",
    "inputs = {\"question\": \"why do the afd Germany party supports PSOE?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUG #2: (DONE) If the provided context is `not_useful`, we need to let know to the query writer to make different queries to the already searched ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: We already harcoded to not search in the RAG but instead running websearch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): None\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 1 queries\n",
      "Warning: No raw_content found for source https://m.facebook.com/GeorgetownCollege/photos/rev-dr-derek-king-sr-nephew-of-dr-martin-luther-king-jr-joined-by-georgetown-col/10154337568592705/\n",
      "Warning: No raw_content found for source https://www.fox21news.com/news/nephew-of-martin-luther-king-jr-commemorates-his-legacy/\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "(\"Martin Luther King Jr.'s nephew is Isaac Newton Farris Jr. He has been \"\n",
      " \"involved in various activities related to his uncle's legacy and has spoken \"\n",
      " 'publicly on social issues.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "#TODO: sample BUG in the graph\n",
    "inputs = {\"question\": \"who is the nephew of martin luther king?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: answer_trivial_question:'\n",
      "('There is no widely recognized historical figure named Francisco Hitler, and '\n",
      " 'Adolf Hitler, the infamous leader of Nazi Germany, did not have a known '\n",
      " 'nephew by that name. If you meant someone else or if this is a fictional or '\n",
      " 'lesser-known figure, please provide more context or clarify your question.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"who is the nephew of Francisco Hitler?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x2041ff869d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app, workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Runnable.astream_events() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastream_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Runnable.astream_events() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "app.astream_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who is the nephew of Francisco Hitler?\", \"news_summary\":text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_chain_start: LangGraph\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The SqliteSaver does not support async methods. Consider using AsyncSqliteSaver instead.\nfrom langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\nNote: AsyncSqliteSaver requires the aiosqlite package to use.\nInstall with:\n`pip install aiosqlite`\nSee https://langchain-ai.github.io/langgraph/reference/checkpoints/asyncsqlitesaverfor more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi!\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream_events(inputs, config\u001b[38;5;241m=\u001b[39mthread,version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      3\u001b[0m     kind \u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1388\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[1;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aclosing(event_stream):\n\u001b[1;32m-> 1388\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m event_stream:\n\u001b[0;32m   1389\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langchain_core\\tracers\\event_stream.py:781\u001b[0m, in \u001b[0;36m_astream_events_implementation_v1\u001b[1;34m(runnable, input, config, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m root_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, runnable\u001b[38;5;241m.\u001b[39mget_name())\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;66;03m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[1;32m--> 781\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m _astream_log_implementation(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     runnable,\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    784\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    785\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    786\u001b[0m     diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    787\u001b[0m     with_streamed_output_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    789\u001b[0m ):\n\u001b[0;32m    790\u001b[0m     run_log \u001b[38;5;241m=\u001b[39m run_log \u001b[38;5;241m+\u001b[39m log\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m encountered_start_event:\n\u001b[0;32m    793\u001b[0m         \u001b[38;5;66;03m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langchain_core\\tracers\\log_stream.py:675\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[1;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;66;03m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(asyncio\u001b[38;5;241m.\u001b[39mCancelledError):\n\u001b[1;32m--> 675\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m task\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langchain_core\\tracers\\log_stream.py:629\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[1;34m()\u001b[0m\n\u001b[0;32m    626\u001b[0m prev_final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    627\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mastream(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    630\u001b[0m     prev_final_output \u001b[38;5;241m=\u001b[39m final_output\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1823\u001b[0m, in \u001b[0;36mPregel.astream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_modes:\n\u001b[0;32m   1818\u001b[0m     config[CONF][CONFIG_KEY_STREAM_WRITER] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1819\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m c: aioloop\u001b[38;5;241m.\u001b[39mcall_soon_threadsafe(\n\u001b[0;32m   1820\u001b[0m             stream\u001b[38;5;241m.\u001b[39mput_nowait, ((), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m, c)\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1822\u001b[0m     )\n\u001b[1;32m-> 1823\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m AsyncPregelLoop(\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1825\u001b[0m     stream\u001b[38;5;241m=\u001b[39mStreamProtocol(stream\u001b[38;5;241m.\u001b[39mput_nowait, stream_modes),\n\u001b[0;32m   1826\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m   1827\u001b[0m     store\u001b[38;5;241m=\u001b[39mstore,\n\u001b[0;32m   1828\u001b[0m     checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer,\n\u001b[0;32m   1829\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\n\u001b[0;32m   1830\u001b[0m     specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[0;32m   1831\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1832\u001b[0m     stream_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_asis,\n\u001b[0;32m   1833\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[0;32m   1834\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[0;32m   1835\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1836\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1837\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[0;32m   1838\u001b[0m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[0;32m   1839\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PregelRunner(\n\u001b[0;32m   1840\u001b[0m         submit\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m   1841\u001b[0m         put_writes\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39mput_writes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1844\u001b[0m         node_finished\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_NODE_FINISHED),\n\u001b[0;32m   1845\u001b[0m     )\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langgraph\\pregel\\loop.py:964\u001b[0m, in \u001b[0;36mAsyncPregelLoop.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CheckpointNotLatest\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer:\n\u001b[1;32m--> 964\u001b[0m     saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer\u001b[38;5;241m.\u001b[39maget_tuple(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_config)\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    966\u001b[0m     saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langgraph\\checkpoint\\sqlite\\__init__.py:466\u001b[0m, in \u001b[0;36mSqliteSaver.aget_tuple\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maget_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[CheckpointTuple]:\n\u001b[0;32m    460\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a checkpoint tuple from the database asynchronously.\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \n\u001b[0;32m    462\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m        This async method is not supported by the SqliteSaver class.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m        Use get_tuple() instead, or consider using [AsyncSqliteSaver][langgraph.checkpoint.sqlite.aio.AsyncSqliteSaver].\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(_AIO_ERROR_MSG)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: The SqliteSaver does not support async methods. Consider using AsyncSqliteSaver instead.\nfrom langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\nNote: AsyncSqliteSaver requires the aiosqlite package to use.\nInstall with:\n`pip install aiosqlite`\nSee https://langchain-ai.github.io/langgraph/reference/checkpoints/asyncsqlitesaverfor more information."
     ]
    }
   ],
   "source": [
    "async for event in app.astream_events(inputs, config=thread,version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    print(f\"{kind}: {event['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The SqliteSaver does not support async methods. Consider using AsyncSqliteSaver instead.\nfrom langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\nNote: AsyncSqliteSaver requires the aiosqlite package to use.\nInstall with:\n`pip install aiosqlite`\nSee https://langchain-ai.github.io/langgraph/reference/checkpoints/asyncsqlitesaverfor more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# messages = [HumanMessage(content=\"What is the weather in SF?\")]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m thread \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream_events({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwho is the nephew of Francisco Hitler?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m:text}, thread, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      5\u001b[0m     kind \u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#we retrieve the events when the llm is otuputting text\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#and then we start showing token by token async\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1388\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[1;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aclosing(event_stream):\n\u001b[1;32m-> 1388\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m event_stream:\n\u001b[0;32m   1389\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langchain_core\\tracers\\event_stream.py:781\u001b[0m, in \u001b[0;36m_astream_events_implementation_v1\u001b[1;34m(runnable, input, config, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m root_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, runnable\u001b[38;5;241m.\u001b[39mget_name())\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;66;03m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[1;32m--> 781\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m _astream_log_implementation(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     runnable,\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    784\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    785\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    786\u001b[0m     diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    787\u001b[0m     with_streamed_output_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    789\u001b[0m ):\n\u001b[0;32m    790\u001b[0m     run_log \u001b[38;5;241m=\u001b[39m run_log \u001b[38;5;241m+\u001b[39m log\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m encountered_start_event:\n\u001b[0;32m    793\u001b[0m         \u001b[38;5;66;03m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langchain_core\\tracers\\log_stream.py:675\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[1;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;66;03m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(asyncio\u001b[38;5;241m.\u001b[39mCancelledError):\n\u001b[1;32m--> 675\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m task\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langchain_core\\tracers\\log_stream.py:629\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[1;34m()\u001b[0m\n\u001b[0;32m    626\u001b[0m prev_final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    627\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mastream(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    630\u001b[0m     prev_final_output \u001b[38;5;241m=\u001b[39m final_output\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1823\u001b[0m, in \u001b[0;36mPregel.astream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_modes:\n\u001b[0;32m   1818\u001b[0m     config[CONF][CONFIG_KEY_STREAM_WRITER] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1819\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m c: aioloop\u001b[38;5;241m.\u001b[39mcall_soon_threadsafe(\n\u001b[0;32m   1820\u001b[0m             stream\u001b[38;5;241m.\u001b[39mput_nowait, ((), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m, c)\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1822\u001b[0m     )\n\u001b[1;32m-> 1823\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m AsyncPregelLoop(\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1825\u001b[0m     stream\u001b[38;5;241m=\u001b[39mStreamProtocol(stream\u001b[38;5;241m.\u001b[39mput_nowait, stream_modes),\n\u001b[0;32m   1826\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m   1827\u001b[0m     store\u001b[38;5;241m=\u001b[39mstore,\n\u001b[0;32m   1828\u001b[0m     checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer,\n\u001b[0;32m   1829\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\n\u001b[0;32m   1830\u001b[0m     specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[0;32m   1831\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1832\u001b[0m     stream_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_asis,\n\u001b[0;32m   1833\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[0;32m   1834\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[0;32m   1835\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1836\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1837\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[0;32m   1838\u001b[0m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[0;32m   1839\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PregelRunner(\n\u001b[0;32m   1840\u001b[0m         submit\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m   1841\u001b[0m         put_writes\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39mput_writes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1844\u001b[0m         node_finished\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_NODE_FINISHED),\n\u001b[0;32m   1845\u001b[0m     )\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langgraph\\pregel\\loop.py:964\u001b[0m, in \u001b[0;36mAsyncPregelLoop.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CheckpointNotLatest\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer:\n\u001b[1;32m--> 964\u001b[0m     saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer\u001b[38;5;241m.\u001b[39maget_tuple(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_config)\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    966\u001b[0m     saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\P - Proyectos en Curso\\ai-curated-articles\\ai_curator\\Lib\\site-packages\\langgraph\\checkpoint\\sqlite\\__init__.py:466\u001b[0m, in \u001b[0;36mSqliteSaver.aget_tuple\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maget_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[CheckpointTuple]:\n\u001b[0;32m    460\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a checkpoint tuple from the database asynchronously.\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \n\u001b[0;32m    462\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m        This async method is not supported by the SqliteSaver class.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m        Use get_tuple() instead, or consider using [AsyncSqliteSaver][langgraph.checkpoint.sqlite.aio.AsyncSqliteSaver].\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(_AIO_ERROR_MSG)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: The SqliteSaver does not support async methods. Consider using AsyncSqliteSaver instead.\nfrom langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\nNote: AsyncSqliteSaver requires the aiosqlite package to use.\nInstall with:\n`pip install aiosqlite`\nSee https://langchain-ai.github.io/langgraph/reference/checkpoints/asyncsqlitesaverfor more information."
     ]
    }
   ],
   "source": [
    "# messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in app.astream_events(, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    \n",
    "    \n",
    "    #we retrieve the events when the llm is otuputting text\n",
    "    #and then we start showing token by token async\n",
    "    \n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): n_queries=3 queries=['AfD Germany support for PSOE Spain', 'AfD and PSOE political relationship', 'AfD Germany PSOE Spain collaboration'] tavily_days=[7, 7, 7] tavily_topic=['news', 'news', 'news']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 2 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "'Finished running: answer_with_docs:'\n",
      "forcing stop of the graph...\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "('The question about the \"grandson of the grandson of Pablo Escobar\" is based '\n",
      " 'on an incorrect assumption. The provided context only gives information '\n",
      " \"about Pablo Escobar's immediate family, including his children, Juan Pablo \"\n",
      " '(also known as Sebastian Marroquin) and Manuela Escobar. There is no mention '\n",
      " 'of any grandchildren, let alone a \"grandson of the grandson.\" Therefore, '\n",
      " 'there is no information available about such a person in the provided '\n",
      " 'context.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"who's the grandson of grandson of pablo escobar?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# inputs = {\"question\": \"Hey, I want to know the last\", \"news_summary\":text}\n",
    "# for output in app.stream(inputs, thread):\n",
    "#     for key, value in output.items():\n",
    "#         pprint(f\"Finished running: {key}:\")\n",
    "# pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUG #5 Caer bucle infinito con `not_useful`, volviendo a ejecutar websearch una y otra vez sin parar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "already searched queries (if applicable): n_queries=3 queries=['Javier Milei meeting with Venezuelan opposition in Argentina', 'reason for Javier Milei and Venezuelan opposition meeting in Argentina', 'Javier Milei Venezuelan opposition meeting January 2025'] tavily_days=[7, 7, 7] tavily_topic=['news', 'news', 'news']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 2 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "forcing stop of the graph...\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "('El atentado en Nueva Orleans ocurriÃ³ el 1 de enero de 2025, cuando '\n",
      " 'Shamsud-Din Jabbar condujo una camioneta elÃ©ctrica hacia una multitud en la '\n",
      " 'calle Bourbon, durante las celebraciones de AÃ±o Nuevo. Este ataque resultÃ³ '\n",
      " 'en la muerte de al menos 14 personas y dejÃ³ a muchas otras heridas. El FBI '\n",
      " 'ha identificado a Jabbar como el sospechoso y estÃ¡ investigando el incidente '\n",
      " 'como un posible acto de terrorismo.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"Â¿QuÃ© ocurriÃ³ en el atentado de Nueva OrleÃ¡s?\", \"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: handle_trivial_question:'\n",
      "'Finished running: retrieve:'\n",
      "'Finished running: grade_documents:'\n",
      "already searched queries (if applicable): n_queries=2 queries=['atentado Nueva Orleans', 'incidente reciente Nueva Orleans'] tavily_days=[7, 7] tavily_topic=['news', 'news']\n",
      "'Finished running: generate_queries:'\n",
      "gonna generate 3 queries\n",
      "'Finished running: websearch:'\n",
      "'Finished running: answer_with_docs:'\n",
      "'Finished running: grade_generation_v_documents_and_question:'\n",
      "('Javier Milei and Venezuelan opposition leader Edmundo GonzÃ¡lez met in '\n",
      " \"Argentina as part of GonzÃ¡lez's international tour. This meeting took place \"\n",
      " \"just days before NicolÃ¡s Maduro's planned inauguration for a third term, \"\n",
      " 'which is not recognized by some countries, including the United States. '\n",
      " 'GonzÃ¡lez, recognized by the U.S. as the legitimate president-elect of '\n",
      " 'Venezuela, is seeking international support and highlighting the plight of '\n",
      " \"Venezuelans under Maduro's regime. The meeting with Milei, a supporter of \"\n",
      " \"the Venezuelan opposition, was a show of solidarity and part of GonzÃ¡lez's \"\n",
      " 'efforts to gather backing for his claim to the presidency.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"why did Javier Milei and the Venezuelan oppositor meet in Argentina?\",\"news_summary\":text}\n",
    "for output in app.stream(inputs, thread):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient()\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.geeksforgeeks.org/lionel-messi-kids/',\n",
       "  'content': \"Who are Lionel Messi's Kids: All About Messi and Antonela 3 Sons - GeeksforGeeks Tutorials Python Tutorial Python Tutorial Python Data Visualization Tutorial Mateo Messi Roccuzzo, born on September 11, 2015, in Barcelona, Spain, is the second son of soccer icon Lionel Messi and Antonela Roccuzzo. Ciro Messi Roccuzzo, the youngest son of soccer superstar Lionel Messi and his wife Antonela Roccuzzo, was born on March 10, 2018, in Barcelona, Spain. Antonela Roccuzzo, born on February 26, 1988, in Rosario, Argentina, is widely known as the wife of soccer superstar Lionel Messi and the mother of their three children. Lionel Messi and Antonela Roccuzzo's three sons, Thiago, Mateo, and Ciro, are growing up in the spotlight, often seen supporting their father's illustrious soccer career. Python Tutorial\"},\n",
       " {'url': 'https://rimpost.com/meet-lionel-messis-three-sons-thiago-mateo-and-ciro',\n",
       "  'content': 'Lionel Messi and Antonella Roccuzzo welcomed their youngest son, Ciro Messi Roccuzzo, on March 10th, 2018. â€˜â€™Ciroâ€™â€™ in the Greek language means sun or lordly, and in Spanish, the name means throne or sun. The couple announced that they were expecting their third child three months after their union.'},\n",
       " {'url': 'https://www.augustman.com/my/sports/lionel-messi-children-in-chronological-order/',\n",
       "  'content': 'Lionel Messiâ€™s youngest son, Ciro Messi Roccuzzo, is six years old as of March 2024. Note: The information in this article is accurate as of the date of publication. celebrities Football Football Players footballers Lionel Messi Sports. written by. Uddipta Banerjee. Senior Digital Writer, Sports and Watches'},\n",
       " {'url': 'https://www.feelingthevibe.com/toplists/leo-messis-kids-meet-his-three-sons-thiago-mateo-ciro/',\n",
       "  'content': 'Meet Thiago Messi â€“ the first born son of Leo and Antonela. He was born on November 2, 2012. He was born on November 2, 2012. He is often seen alongside his mother and two brothers cheering his father on whether he is playing for his home team of Argentina or in the US at his newest venture with Inter Miami.'},\n",
       " {'url': 'https://www.sportsdave.com/who-is-mateo-messi-fact-about-lionel-messis-son/',\n",
       "  'content': 'ALSO, READ: Biography of Jorge Messi,( Lionel Messiâ€™s father) Lionel Messi children: Meet Mateo Messi, Thiago, Ciro. Messi and Roccuzzo, childhood friends who reconnected in 2005, welcomed their first child, Thiago, in 2012. Mateo Messi, their second son, was born in 2015, and Ciro, their third son, was born in 2018.'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search_tool.invoke(\"son of leo messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Search Results (k=3):\n",
      "[{'url': 'https://www.britannica.com/technology/artificial-intelligence', 'content': 'For example, a program that learns the past tense of regular English verbs by rote will not be able to produce the past tense of a word such as jump unless it previously had been presented with jumped, whereas a program that is able to generalize can learn the â€œadd edâ€ rule and so form the past tense of jump based on experience with similar verbs. The real nature of the waspâ€™s instinctual behaviour is revealed if the food is moved a few inches away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as often as the food is displaced. The program might then store the solution with the position so that the next time the computer encountered the same position it would recall the solution. Artificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the\\xa0intellectual\\xa0processes characteristic of humans, such as the ability to reason. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience.'}, {'url': 'https://cloud.google.com/learn/what-is-artificial-intelligence', 'content': 'Solution\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nTake the next step\\nStart\\nbuilding on Google Cloud with $300 in free credits and 20+\\nalways free products.\\n Artificial intelligence (AI) is a set of technologies\\nthat enable computers to perform a variety of advanced\\nfunctions, including the ability to\\nsee,\\nunderstand and\\ntranslate spoken and written language,\\nanalyze data,\\nmake recommendations, and more.\\n Artificial intelligence\\ndefined\\nArtificial intelligence is a field of science\\nconcerned with building computers and machines that\\ncan reason, learn, and act in such a way that would\\nnormally require human intelligence or that involves\\ndata whose scale exceeds what humans can\\nanalyze.\\n By using products like\\nVertex AI,\\nCCAI,\\nDocAI,\\nor AI APIs, organizations can make sense of all the data\\ntheyâ€™re producing, collecting, or otherwise analyzing,\\nno matter what format itâ€™s in, to make actionable\\nbusiness decisions.\\n On an operational level for business use, AI is a\\nset of technologies that are based primarily on\\nmachine learning and deep learning, used for data\\nanalytics, predictions and forecasting, object\\ncategorization, natural language processing,\\nrecommendations, intelligent data retrieval, and\\nmore.\\n'}, {'url': 'https://ai.engineering.columbia.edu/ai-vs-machine-learning/', 'content': 'Home / Artificial Intelligence (AI) vs. Machine Learning\\nArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine Learning\\nArtificial intelligence (AI) and machine learning are often used interchangeably, but machine learning is a subset of the broader category of AI.\\n Computer programmers and software developers enable computers to analyze data and solve problems â€” essentially, they create artificial intelligence systems â€” by applying tools such as:\\nBelow is a breakdown of the differences between artificial intelligence and machine learning as well as how they are being applied in organizations large and small today.\\n Put in context, artificial intelligence refers to the general ability of computers to emulate human\\xa0thought and perform tasks in real-world environments, while machine learning refers to the technologies and algorithms that enable systems to identify patterns, make decisions, and improve themselves through experience and data.\\n Artificial intelligence can help manufacturing leaders automate their business processes by applying data analytics and machine learning to applications such as the following:\\nAI and Machine Learning in Banking\\nData privacy and security are especially critical within the banking industry. Financial services leaders can keep customer data secure while increasing efficiencies using AI and machine learning in several ways:\\nAI Applications in Health Care\\nThe health care field uses huge amounts of data and increasingly relies on informatics and analytics to provide accurate, efficient health services.'}, {'url': 'https://en.wikipedia.org/wiki/A.I._Artificial_Intelligence', 'content': 'But it\\'s a brilliant piece of film and of course it\\'s a phenomenon because it contains the energies and talents of two brilliant filmmakers\".[50] Richard Corliss heavily praised Spielberg\\'s direction, as well as the cast and visual effects.[51]\\nRoger Ebert gave the film three stars out of a possible four, saying that it is \"wonderful and maddening\".[52] Ebert later gave the film a full four stars and added it to his \"Great Movies\" list in 2011.[53] Leonard Maltin, on the other hand, gives the film two stars out of four in his Movie Guide, writing: \"[The] intriguing story draws us in, thanks in part to Osment\\'s exceptional performance, but takes several wrong turns; ultimately, it just doesn\\'t work. Plus, quite a few critics in America misunderstood the film, thinking for instance that the Giacometti-style beings in the final 20 minutes were aliens (whereas they were robots of the future who had evolved themselves from the robots in the earlier part of the film) and also thinking that the final 20 minutes were a sentimental addition by Spielberg, whereas those scenes were exactly what I wrote for Stanley and exactly what he wanted, filmed faithfully by Spielberg. However, Spielberg asked Angel to be on the set every day to make line alterations wherever he felt necessary.[32] Social robotics expert Cynthia Breazeal served as technical consultant during production.[21][33] Costume designer Bob Ringwood studied pedestrians on the Las Vegas Strip for his influence on the Rouge City extras.[34] Additional visual effects such as removing the visible rods controlling Teddy and removing Haley Joel Osment\\'s breath, were provided in-house by PDI/DreamWorks.[35]\\nCasting[edit]\\nJulianne Moore and Gwyneth Paltrow were considered for the role of Monica Swinton before Frances O\\'Connor was cast and Jerry Seinfeld was originally considered to voice and play the Comedian Robot before Chris Rock was cast.[36]\\nSoundtrack[edit]\\n To avoid audiences mistaking A.I. for a family film, no action figures were created, although Hasbro released a talking Teddy following the film\\'s release in June 2001.[21]\\nA.I. premiered at the Venice Film Festival in 2001.[38]\\nHome media[edit]\\nA.I. Artificial Intelligence was released on VHS and DVD in the United States by DreamWorks Home Entertainment on March 5, 2002[39][40] in widescreen and full-screen 2-disc special editions featuring an extensive sixteen-part documentary detailing the film\\'s development, production, music and visual effects. After the release of Spielberg\\'s Jurassic Park, with its innovative computer-generated imagery, it was announced in November 1993 that production of A.I. would begin in 1994.[16] Dennis Muren and Ned Gorman, who worked on Jurassic Park, became visual effects supervisors,[13] but Kubrick was displeased with their previsualization, and with the expense of hiring Industrial Light & Magic.[17]\\n\"Stanley [Kubrick] showed Steven [Spielberg] 650 drawings which he had, and the script and the story, everything.'}, {'url': 'https://www.sas.com/en_us/insights/analytics/what-is-artificial-intelligence.html', 'content': \"Next Steps\\nSee how Artificial Intelligence Solutions augment human creativity and endeavors with AI.\\nFeatured product for ARTIFICIAL INTELLIGENCE\\nSASÂ®\\xa0Visual Data Mining and Machine Learning\\nAI is simplified when you can prepare data for analysis, develop models with modern machine-learning algorithms and integrate\\xa0text analytics\\xa0all in one product. Learn more about SAS\\nSelect Your Region\\nAmericas\\nEurope\\nMiddle East & Africa\\nAsia Pacific\\nAmericas\\nEurope\\nMiddle East & Africa\\nAsia Pacific\\nHi !\\n Keep reading for modern examples of artificial intelligence in health care, retail and more.\\n1950sâ€“1970s\\nNeural Networks\\nEarly work with neural networks stirs excitement for â€œthinking machines.â€\\n1980sâ€“2010s\\nMachine Learning\\nMachine learning becomes popular.\\n Advance your career and train your team in sought after skills\\nWhy Learn SAS?\\nWhy SAS?\\nLearn why SAS is the world's most trusted analytics platform, and why analysts, customers and industry experts love SAS.\\n Artificial Intelligence trends to watch\\nQuick, watch this video to hear AI experts and data science pros weigh in on AI trends for the next decade.\\n\"}]\n",
      "Length of LangChain results: 5\n",
      "\n",
      "Tavily API Search Results (max_results=3):\n",
      "{'query': 'Artificial Intelligence', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Artificial intelligence (AI) | Definition, Examples, Types, Applications, Companies, & Facts', 'url': 'https://www.britannica.com/technology/artificial-intelligence', 'content': 'For example, a program that learns the past tense of regular English verbs by rote will not be able to produce the past tense of a word such as jump unless it previously had been presented with jumped, whereas a program that is able to generalize can learn the â€œadd edâ€ rule and so form the past tense of jump based on experience with similar verbs. The real nature of the waspâ€™s instinctual behaviour is revealed if the food is moved a few inches away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as often as the food is displaced. The program might then store the solution with the position so that the next time the computer encountered the same position it would recall the solution. Artificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the\\xa0intellectual\\xa0processes characteristic of humans, such as the ability to reason. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience.', 'score': 0.88372874, 'raw_content': 'artificial intelligence\\nOur editors will review what youâ€™ve submitted and determine whether to revise the article.\\nOur editors will review what youâ€™ve submitted and determine whether to revise the article.\\nRecent News\\nWhat is artificial intelligence?\\nArtificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the\\xa0intellectual\\xa0processes characteristic of humans, such as the ability to reason. Although there are as yet no AIs that match full human flexibility over wider domains or in tasks requiring much everyday knowledge, some AIs perform specific tasks as well as humans. Learn more.\\nAre artificial intelligence and machine learning the same?\\nNo, artificial intelligence and machine learning are not the same, but they are closely related. Machine learning is the method to train a computer to learn from its inputs but without explicit programming for every circumstance. Machine learning helps a computer to achieve artificial intelligence.\\nartificial intelligence (AI),\\nthe ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience. Since the development of the digital computer in the 1940s, it has been demonstrated that computers can be programmed to carry out very complex tasksâ€”such as discovering proofs for mathematical theorems or playing chessâ€”with great proficiency. Still, despite continuing advances in computer processing speed and memory capacity, there are as yet no programs that can match full human flexibility over wider domains or in tasks requiring much everyday knowledge. On the other hand, some programs have attained the performance levels of human experts and professionals in performing certain specific tasks, so that artificial intelligence in this limited sense is found in applications as diverse as medical diagnosis, computer search engines, voice or handwriting recognition, and chatbots.\\n(Read Ray Kurzweilâ€™s Britannica essay on the future of â€œNonbiological Man.â€)\\nWhat is intelligence?\\nAll but the simplest human behaviour is ascribed to intelligence, while even the most complicated insect behaviour is usually not taken as an indication of intelligence. What is the difference? Consider the behaviour of the digger wasp, Sphex ichneumoneus. When the female wasp returns to her burrow with food, she first deposits it on the threshold, checks for intruders inside her burrow, and only then, if the coast is clear, carries her food inside. The real nature of the waspâ€™s instinctual behaviour is revealed if the food is moved a few inches away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as often as the food is displaced. Intelligenceâ€”conspicuously absent in the case of Sphexâ€”must include the ability to adapt to new circumstances.\\n(Read Yuval Noah Harariâ€™s Britannica essay on the future of â€œNonconscious Man.â€)\\nPsychologists generally characterize human intelligence not by just one trait but by the combination of many diverse abilities. Research in AI has focused chiefly on the following components of intelligence: learning, reasoning, problem solving, perception, and using language.\\nLearning\\nThere are a number of different forms of learning as applied to artificial intelligence. The simplest is learning by trial and error. For example, a simple computer program for solving mate-in-one chess problems might try moves at random until mate is found. The program might then store the solution with the position so that the next time the computer encountered the same position it would recall the solution. This simple memorizing of individual items and proceduresâ€”known as rote learningâ€”is relatively easy to implement on a computer. More challenging is the problem of implementing what is called generalization. Generalization involves applying past experience to analogous new situations. For example, a program that learns the past tense of regular English verbs by rote will not be able to produce the past tense of a word such as jump unless it previously had been presented with jumped, whereas a program that is able to generalize can learn the â€œadd edâ€ rule and so form the past tense of jump based on experience with similar verbs.'}, {'title': 'What Is Artificial Intelligence (AI)? | Google Cloud', 'url': 'https://cloud.google.com/learn/what-is-artificial-intelligence', 'content': 'Solution\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nTake the next step\\nStart\\nbuilding on Google Cloud with $300 in free credits and 20+\\nalways free products.\\n Artificial intelligence (AI) is a set of technologies\\nthat enable computers to perform a variety of advanced\\nfunctions, including the ability to\\nsee,\\nunderstand and\\ntranslate spoken and written language,\\nanalyze data,\\nmake recommendations, and more.\\n Artificial intelligence\\ndefined\\nArtificial intelligence is a field of science\\nconcerned with building computers and machines that\\ncan reason, learn, and act in such a way that would\\nnormally require human intelligence or that involves\\ndata whose scale exceeds what humans can\\nanalyze.\\n By using products like\\nVertex AI,\\nCCAI,\\nDocAI,\\nor AI APIs, organizations can make sense of all the data\\ntheyâ€™re producing, collecting, or otherwise analyzing,\\nno matter what format itâ€™s in, to make actionable\\nbusiness decisions.\\n On an operational level for business use, AI is a\\nset of technologies that are based primarily on\\nmachine learning and deep learning, used for data\\nanalytics, predictions and forecasting, object\\ncategorization, natural language processing,\\nrecommendations, intelligent data retrieval, and\\nmore.\\n', 'score': 0.77751994, 'raw_content': 'What is Artificial\\nIntelligence (AI)?\\nArtificial intelligence (AI) is a set of technologies\\nthat enable computers to perform a variety of advanced\\nfunctions, including the ability to\\nsee,\\nunderstand and\\ntranslate spoken and written language,\\nanalyze data,\\nmake recommendations, and more.\\nAI is the backbone of innovation in modern computing,\\nunlocking value for individuals and businesses. For\\nexample,\\noptical character recognition (OCR)\\nuses AI to extract text and data from images and\\ndocuments, turns unstructured content into\\nbusiness-ready structured data, and unlocks valuable\\ninsights.\\nReady to get started? New customers get $300 in free\\ncredits to spend on Google Cloud.\\nArtificial intelligence\\ndefined\\nArtificial intelligence is a field of science\\nconcerned with building computers and machines that\\ncan reason, learn, and act in such a way that would\\nnormally require human intelligence or that involves\\ndata whose scale exceeds what humans can\\nanalyze.\\nAI is a broad field that encompasses many different\\ndisciplines, including computer science, data\\nanalytics and statistics, hardware and software\\nengineering, linguistics, neuroscience, and even\\nphilosophy and psychology.\\nOn an operational level for business use, AI is a\\nset of technologies that are based primarily on\\nmachine learning and deep learning, used for data\\nanalytics, predictions and forecasting, object\\ncategorization, natural language processing,\\nrecommendations, intelligent data retrieval, and\\nmore.\\nTypes of artificial\\nintelligence\\nArtificial intelligence can be organized in several ways,\\ndepending on stages of development or actions being\\nperformed.\\nFor instance, four stages of AI development are commonly\\nrecognized.\\nA more useful way of broadly categorizing types of\\nartificial intelligence is by what the machine can do. All\\nof what we currently call artificial intelligence is\\nconsidered artificial â€œnarrowâ€ intelligence, in that it can\\nperform only narrow sets of actions based on its programming\\nand training. For instance, an AI algorithm that is used for\\nobject classification wonâ€™t be able to perform natural\\nlanguage processing. Google Search is a form of narrow AI,\\nas is predictive analytics, or virtual assistants.\\nArtificial general intelligence (AGI) would be the ability\\nfor a machine to â€œsense, think, and actâ€ just like a human.\\nAGI does not currently exist. The next level would be\\nartificial superintelligence (ASI), in which the machine\\nwould be able to function in all ways superior to a\\nhuman.\\nArtificial intelligence\\ntraining models\\nWhen businesses talk about AI, they often talk about\\nâ€œtraining data.â€ But what does that mean? Remember that\\nlimited-memory artificial intelligence is AI that improves\\nover time by being trained with new data. Machine learning\\nis a\\nsubset of artificial intelligence\\nthat uses algorithms to train data to obtain results.\\nIn broad strokes, three kinds of learnings models are often\\nused in machine learning:\\nSupervised learning is a machine learning model that\\nmaps a specific input to an output using labeled training\\ndata (structured data). In simple terms, to train the\\nalgorithm to recognize pictures of cats, feed it pictures\\nlabeled as cats.\\nUnsupervised learning is a machine learning model\\nthat learns patterns based on unlabeled data (unstructured\\ndata). Unlike supervised learning, the end result is not\\nknown ahead of time. Rather, the algorithm learns\\nfrom the data, categorizing it into groups based on\\nattributes. For instance, unsupervised learning is good at\\npattern matching and descriptive modeling.\\nIn addition to supervised and unsupervised learning, a\\nmixed approach called semi-supervised learning is often\\nemployed, where only some of the data is labeled. In\\nsemi-supervised learning, an end result is known, but the\\nalgorithm must figure out how to organize and structure the\\ndata to achieve the desired results.\\nReinforcement learning is a machine learning model\\nthat can be broadly described as â€œlearn by doing.â€ An\\nâ€œagentâ€ learns to perform a defined task by trial and error\\n(a feedback loop) until its performance is within a\\ndesirable range. The agent receives positive reinforcement\\nwhen it performs the task well and negative reinforcement\\nwhen it performs poorly. An example of reinforcement\\nlearning would be teaching a robotic hand to pick up a\\nball.\\nCommon types of artificial\\nneural networks\\nA common type of training model in AI is an artificial\\nneural network, a model loosely based on the human\\nbrain.\\nA neural network is a system of artificial\\nneuronsâ€”sometimes called perceptronsâ€”that are computational\\nnodes used to classify and analyze data. The data is fed\\ninto the first layer of a neural network, with each\\nperceptron making a decision, then passing that information\\nonto multiple nodes in the next layer. Training models with\\nmore than three layers are referred to as â€œdeep neural\\nnetworksâ€ or â€œdeep learning.â€ Some modern neural networks\\nhave hundreds or thousands of layers. The output of the\\nfinal perceptrons accomplish the task set to the neural\\nnetwork, such as classify an object or find patterns in\\ndata.\\nSome of the most common types of artificial neural networks\\nyou may encounter include:\\nFeedforward neural networks (FF) are one of the\\noldest forms of neural networks, with data flowing one way\\nthrough layers of artificial neurons until the output is\\nachieved. In modern days, most feedforward neural networks\\nare considered â€œdeep feedforwardâ€ with several layers\\n(and more than one â€œhiddenâ€ layer). Feedforward neural\\nnetworks are typically paired with an error-correction\\nalgorithm called â€œbackpropagationâ€ that, in simple terms,\\nstarts with the result of the neural network and works back\\nthrough to the beginning, finding errors to improve the\\naccuracy of the neural network. Many simple but powerful\\nneural networks are deep feedforward.\\nRecurrent neural networks (RNN) differ from\\nfeedforward neural networks in that they typically use time\\nseries data or data that involves sequences. Unlike\\nfeedforward neural networks, which use weights in each node\\nof the network, recurrent neural networks have â€œmemoryâ€ of\\nwhat happened in the previous layer as contingent to the\\noutput of the current layer. For instance, when performing\\nnatural language processing, RNNs can â€œkeep in mindâ€ other\\nwords used in a sentence. RNNs are often used for speech\\nrecognition, translation, and to caption images.\\nLong/short term memory (LSTM) are an advanced form\\nof RNN that can use memory to â€œrememberâ€ what happened in\\nprevious layers. The difference between RNNs and LTSM is\\nthat LTSM can remember what happened several layers ago,\\nthrough the use of â€œmemory cells.â€ LSTM is often used in\\nspeech recognition and making predictions.\\nConvolutional neural networks (CNN) include some\\nof the most common neural networks in modern artificial\\nintelligence. Most often used in image recognition, CNNs use\\nseveral distinct layers (a convolutional layer, then a\\npooling layer) that filter different parts of an image\\nbefore putting it back together (in the fully connected\\nlayer). The earlier convolutional layers may look for simple\\nfeatures of an image such as colors and edges, before\\nlooking for more complex features in additional layers.\\nGenerative adversarial networks (GAN) involve two\\nneural networks competing against each other in a game that\\nultimately improves the accuracy of the output. One network\\n(the generator) creates examples that the other network (the\\ndiscriminator) attempts to prove true or false. GANs have\\nbeen used to create realistic images and even make art.\\nBenefits of AI\\nAutomation\\nAI can automate workflows and processes or work\\nindependently and autonomously from a human team. For\\nexample, AI can help automate aspects of cybersecurity\\nby continuously monitoring and analyzing network\\ntraffic. Similarly, a smart factory may have dozens of\\ndifferent kinds of AI in use, such as robots using\\ncomputer vision to navigate the factory floor or to\\ninspect products for defects, create digital twins, or\\nuse real-time analytics to measure efficiency and\\noutput.\\nReduce human error\\nAI can eliminate manual errors in data processing,\\nanalytics, assembly in manufacturing, and other tasks\\nthrough automation and algorithms that follow the same\\nprocesses every single time.\\nEliminate repetitive tasks\\nAI can be used to perform repetitive tasks, freeing\\nhuman capital to work on higher impact problems. AI can\\nbe used to automate processes, like verifying documents,\\ntranscribing phone calls, or answering simple customer\\nquestions like â€œwhat time do you close?â€ Robots are\\noften used to perform â€œdull, dirty, or dangerousâ€ tasks\\nin the place of a human.\\nFast and accurate\\nAI can process more information more quickly than a\\nhuman, finding patterns and discovering relationships in\\ndata that a human may miss.\\nInfinite availability\\nAI is not limited by time of day, the need for breaks,\\nor other human encumbrances. When running in the cloud,\\nAI and machine learning can be â€œalways on,â€ continuously\\nworking on its assigned tasks.\\nAccelerated research and development\\nThe ability to analyze vast amounts of data quickly can\\nlead to accelerated breakthroughs in research and\\ndevelopment. For instance, AI has been used in\\npredictive modeling of potential new pharmaceutical\\ntreatments, or to quantify the human genome.\\nSolve your business challenges with Google Cloud\\nApplications and use cases for artificial intelligence\\nSpeech recognition\\nAutomatically convert spoken speech into written text.\\nImage recognition\\nIdentify and categorize various aspects of an image.\\nTranslation\\nTranslate written or spoken words from one language\\ninto another.\\nPredictive modeling\\nMine data to forecast specific outcomes with high\\ndegrees of granularity.\\nData analytics\\nFind patterns and relationships in data for business\\nintelligence.\\nCybersecurity\\nAutonomously scan networks for cyber attacks and\\nthreats.\\nRelated products and services\\nGoogle offers a number of sophisticated artificial\\nintelligence products, solutions, and applications on a\\ntrusted cloud platform that enables businesses to easily\\nbuild and implement AI algorithms and models.\\nBy using products like\\nVertex AI,\\nCCAI,\\nDocAI,\\nor AI APIs, organizations can make sense of all the data\\ntheyâ€™re producing, collecting, or otherwise analyzing,\\nno matter what format itâ€™s in, to make actionable\\nbusiness decisions.\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nTake the next step\\nStart\\nbuilding on Google Cloud with $300 in free credits and 20+\\nalways free products.\\nTake the next step\\nStart\\nyour next project, explore interactive tutorials, and\\nmanage your account.\\nWhy Google\\nProducts and pricing\\nSolutions\\nResources\\nEngage'}, {'title': 'Artificial Intelligence (AI) vs. Machine Learning | Columbia AI', 'url': 'https://ai.engineering.columbia.edu/ai-vs-machine-learning/', 'content': 'Home / Artificial Intelligence (AI) vs. Machine Learning\\nArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine Learning\\nArtificial intelligence (AI) and machine learning are often used interchangeably, but machine learning is a subset of the broader category of AI.\\n Computer programmers and software developers enable computers to analyze data and solve problems â€” essentially, they create artificial intelligence systems â€” by applying tools such as:\\nBelow is a breakdown of the differences between artificial intelligence and machine learning as well as how they are being applied in organizations large and small today.\\n Put in context, artificial intelligence refers to the general ability of computers to emulate human\\xa0thought and perform tasks in real-world environments, while machine learning refers to the technologies and algorithms that enable systems to identify patterns, make decisions, and improve themselves through experience and data.\\n Artificial intelligence can help manufacturing leaders automate their business processes by applying data analytics and machine learning to applications such as the following:\\nAI and Machine Learning in Banking\\nData privacy and security are especially critical within the banking industry. Financial services leaders can keep customer data secure while increasing efficiencies using AI and machine learning in several ways:\\nAI Applications in Health Care\\nThe health care field uses huge amounts of data and increasingly relies on informatics and analytics to provide accurate, efficient health services.', 'score': 0.74652773, 'raw_content': 'Home / Artificial Intelligence (AI) vs. Machine Learning\\nArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine Learning\\nArtificial intelligence (AI) and machine learning are often used interchangeably, but machine learning is a subset of the broader category of AI.\\nPut in context, artificial intelligence refers to the general ability of computers to emulate human\\xa0thought and perform tasks in real-world environments, while machine learning refers to the technologies and algorithms that enable systems to identify patterns, make decisions, and improve themselves through experience and data.\\nComputer programmers and software developers enable computers to analyze data and solve problems â€” essentially, they create artificial intelligence systems â€” by applying tools such as:\\nBelow is a breakdown of the differences between artificial intelligence and machine learning as well as how they are being applied in organizations large and small today.\\nWhat Is Artificial Intelligence?\\nArtificial Intelligence is the field of developing computers and robots that are capable of behaving in ways that both mimic and go beyond human capabilities. AI-enabled programs can analyze and contextualize data to provide information or automatically trigger actions without human interference.\\nToday, artificial intelligence is at the heart of many technologies we use, including smart devices and voice assistants such as Siri on Apple devices. Companies are incorporating techniques such as natural language processing and computer vision â€” the ability for computers to use human language and interpret images \\xadâ€” to automate tasks, accelerate decision making, and enable customer conversations with chatbots.\\nWhat Is Machine Learning?\\nMachine learning is a pathway to artificial intelligence. This subcategory of AI uses algorithms to automatically learn insights and recognize patterns from data, applying that learning to make increasingly better decisions.\\nBy studying and experimenting with machine learning, programmers test the limits of how much they can improve the perception, cognition, and action of a computer system.\\nDeep learning, an advanced method of machine learning, goes a step further. Deep learning models use large neural networks â€” networks that function like a human brain to logically analyze data â€” to learn complex patterns and make predictions independent of human input.\\nHow Companies Use AI and Machine Learning\\nTo be successful in nearly any industry, organizations must be able to transform their data into actionable insight. Artificial Intelligence and machine learning give organizations the advantage of automating a variety of manual processes involving data and decision making.\\nBy incorporating AI and machine learning into their systems and strategic plans, leaders can understand and act on data-driven insights with greater speed and efficiency.\\nAI in the Manufacturing Industry\\nEfficiency is key to the success of an organization in the manufacturing industry. Artificial intelligence can help manufacturing leaders automate their business processes by applying data analytics and machine learning to applications such as the following:\\nAI and Machine Learning in Banking\\nData privacy and security are especially critical within the banking industry. Financial services leaders can keep customer data secure while increasing efficiencies using AI and machine learning in several ways:\\nAI Applications in Health Care\\nThe health care field uses huge amounts of data and increasingly relies on informatics and analytics to provide accurate, efficient health services. AI tools can help improve patient outcomes, save time, and even help providers avoid burnout by:\\nLearn more about how AI is changing the world of health care.\\nThe online Artificial Intelligence executive certificate program, offered through the Fu Foundation School of Engineering and Applied Science at Columbia University, prepares you with the skills and insights to drive AI strategy and adoption across your organization.\\nWith courses that address algorithms, machine learning, data privacy, robotics, and other AI topics, this non-credit program is designed for forward-thinking team leaders and technically proficient professionals who want to gain a deeper understanding of the applications of AI. You can complete the program in 18 months while continuing to work.\\nRequest Information\\nRequest Information\\nRequest Information'}], 'response_time': 2.34}\n",
      "Length of Tavily API results: 6\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import TavilySearchResults\n",
    "# import tavily_client  # Assuming Tavily API is installed and set up\n",
    "\n",
    "# Use LangChain's TavilySearchResults with 'k' to control results for speed\n",
    "def search_with_langchain(query, k):\n",
    "    # Initialize the LangChain TavilySearchResults tool with 'k'\n",
    "    web_search_tool = TavilySearchResults(k=k)\n",
    "    results = web_search_tool.invoke(query)\n",
    "    return results\n",
    "\n",
    "# Use Tavily API client directly with 'max_results' to control speed\n",
    "def search_with_tavily_api(query, max_results):\n",
    "    result = tavily_client.search(\n",
    "        query,\n",
    "        max_results=max_results,  # Set the number of results\n",
    "        include_raw_content=True,\n",
    "        topic=\"general\"\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# Test the functions with query\n",
    "query = \"Artificial Intelligence\"\n",
    "\n",
    "# Test with LangChain's TavilySearchResults (using 'k')\n",
    "print(\"LangChain Search Results (k=3):\")\n",
    "langchain_results = search_with_langchain(query, k=3)\n",
    "print(langchain_results)\n",
    "print(f\"Length of LangChain results: {len(langchain_results)}\\n\")\n",
    "\n",
    "# Test with Tavily API Client (using 'max_results')\n",
    "print(\"Tavily API Search Results (max_results=3):\")\n",
    "tavily_api_results = search_with_tavily_api(query, max_results=3)\n",
    "print(tavily_api_results)\n",
    "print(f\"Length of Tavily API results: {len(tavily_api_results)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.britannica.com/technology/artificial-intelligence',\n",
       "  'content': 'For example, a program that learns the past tense of regular English verbs by rote will not be able to produce the past tense of a word such as jump unless it previously had been presented with jumped, whereas a program that is able to generalize can learn the â€œadd edâ€ rule and so form the past tense of jump based on experience with similar verbs. The real nature of the waspâ€™s instinctual behaviour is revealed if the food is moved a few inches away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as often as the food is displaced. The program might then store the solution with the position so that the next time the computer encountered the same position it would recall the solution. Artificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the\\xa0intellectual\\xa0processes characteristic of humans, such as the ability to reason. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience.'},\n",
       " {'url': 'https://cloud.google.com/learn/what-is-artificial-intelligence',\n",
       "  'content': 'Solution\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nTake the next step\\nStart\\nbuilding on Google Cloud with $300 in free credits and 20+\\nalways free products.\\n Artificial intelligence (AI) is a set of technologies\\nthat enable computers to perform a variety of advanced\\nfunctions, including the ability to\\nsee,\\nunderstand and\\ntranslate spoken and written language,\\nanalyze data,\\nmake recommendations, and more.\\n Artificial intelligence\\ndefined\\nArtificial intelligence is a field of science\\nconcerned with building computers and machines that\\ncan reason, learn, and act in such a way that would\\nnormally require human intelligence or that involves\\ndata whose scale exceeds what humans can\\nanalyze.\\n By using products like\\nVertex AI,\\nCCAI,\\nDocAI,\\nor AI APIs, organizations can make sense of all the data\\ntheyâ€™re producing, collecting, or otherwise analyzing,\\nno matter what format itâ€™s in, to make actionable\\nbusiness decisions.\\n On an operational level for business use, AI is a\\nset of technologies that are based primarily on\\nmachine learning and deep learning, used for data\\nanalytics, predictions and forecasting, object\\ncategorization, natural language processing,\\nrecommendations, intelligent data retrieval, and\\nmore.\\n'},\n",
       " {'url': 'https://ai.engineering.columbia.edu/ai-vs-machine-learning/',\n",
       "  'content': 'Home / Artificial Intelligence (AI) vs. Machine Learning\\nArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine Learning\\nArtificial intelligence (AI) and machine learning are often used interchangeably, but machine learning is a subset of the broader category of AI.\\n Computer programmers and software developers enable computers to analyze data and solve problems â€” essentially, they create artificial intelligence systems â€” by applying tools such as:\\nBelow is a breakdown of the differences between artificial intelligence and machine learning as well as how they are being applied in organizations large and small today.\\n Put in context, artificial intelligence refers to the general ability of computers to emulate human\\xa0thought and perform tasks in real-world environments, while machine learning refers to the technologies and algorithms that enable systems to identify patterns, make decisions, and improve themselves through experience and data.\\n Artificial intelligence can help manufacturing leaders automate their business processes by applying data analytics and machine learning to applications such as the following:\\nAI and Machine Learning in Banking\\nData privacy and security are especially critical within the banking industry. Financial services leaders can keep customer data secure while increasing efficiencies using AI and machine learning in several ways:\\nAI Applications in Health Care\\nThe health care field uses huge amounts of data and increasingly relies on informatics and analytics to provide accurate, efficient health services.'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/A.I._Artificial_Intelligence',\n",
       "  'content': 'But it\\'s a brilliant piece of film and of course it\\'s a phenomenon because it contains the energies and talents of two brilliant filmmakers\".[50] Richard Corliss heavily praised Spielberg\\'s direction, as well as the cast and visual effects.[51]\\nRoger Ebert gave the film three stars out of a possible four, saying that it is \"wonderful and maddening\".[52] Ebert later gave the film a full four stars and added it to his \"Great Movies\" list in 2011.[53] Leonard Maltin, on the other hand, gives the film two stars out of four in his Movie Guide, writing: \"[The] intriguing story draws us in, thanks in part to Osment\\'s exceptional performance, but takes several wrong turns; ultimately, it just doesn\\'t work. Plus, quite a few critics in America misunderstood the film, thinking for instance that the Giacometti-style beings in the final 20 minutes were aliens (whereas they were robots of the future who had evolved themselves from the robots in the earlier part of the film) and also thinking that the final 20 minutes were a sentimental addition by Spielberg, whereas those scenes were exactly what I wrote for Stanley and exactly what he wanted, filmed faithfully by Spielberg. However, Spielberg asked Angel to be on the set every day to make line alterations wherever he felt necessary.[32] Social robotics expert Cynthia Breazeal served as technical consultant during production.[21][33] Costume designer Bob Ringwood studied pedestrians on the Las Vegas Strip for his influence on the Rouge City extras.[34] Additional visual effects such as removing the visible rods controlling Teddy and removing Haley Joel Osment\\'s breath, were provided in-house by PDI/DreamWorks.[35]\\nCasting[edit]\\nJulianne Moore and Gwyneth Paltrow were considered for the role of Monica Swinton before Frances O\\'Connor was cast and Jerry Seinfeld was originally considered to voice and play the Comedian Robot before Chris Rock was cast.[36]\\nSoundtrack[edit]\\n To avoid audiences mistaking A.I. for a family film, no action figures were created, although Hasbro released a talking Teddy following the film\\'s release in June 2001.[21]\\nA.I. premiered at the Venice Film Festival in 2001.[38]\\nHome media[edit]\\nA.I. Artificial Intelligence was released on VHS and DVD in the United States by DreamWorks Home Entertainment on March 5, 2002[39][40] in widescreen and full-screen 2-disc special editions featuring an extensive sixteen-part documentary detailing the film\\'s development, production, music and visual effects. After the release of Spielberg\\'s Jurassic Park, with its innovative computer-generated imagery, it was announced in November 1993 that production of A.I. would begin in 1994.[16] Dennis Muren and Ned Gorman, who worked on Jurassic Park, became visual effects supervisors,[13] but Kubrick was displeased with their previsualization, and with the expense of hiring Industrial Light & Magic.[17]\\n\"Stanley [Kubrick] showed Steven [Spielberg] 650 drawings which he had, and the script and the story, everything.'},\n",
       " {'url': 'https://www.sas.com/en_us/insights/analytics/what-is-artificial-intelligence.html',\n",
       "  'content': \"Next Steps\\nSee how Artificial Intelligence Solutions augment human creativity and endeavors with AI.\\nFeatured product for ARTIFICIAL INTELLIGENCE\\nSASÂ®\\xa0Visual Data Mining and Machine Learning\\nAI is simplified when you can prepare data for analysis, develop models with modern machine-learning algorithms and integrate\\xa0text analytics\\xa0all in one product. Learn more about SAS\\nSelect Your Region\\nAmericas\\nEurope\\nMiddle East & Africa\\nAsia Pacific\\nAmericas\\nEurope\\nMiddle East & Africa\\nAsia Pacific\\nHi !\\n Keep reading for modern examples of artificial intelligence in health care, retail and more.\\n1950sâ€“1970s\\nNeural Networks\\nEarly work with neural networks stirs excitement for â€œthinking machines.â€\\n1980sâ€“2010s\\nMachine Learning\\nMachine learning becomes popular.\\n Advance your career and train your team in sought after skills\\nWhy Learn SAS?\\nWhy SAS?\\nLearn why SAS is the world's most trusted analytics platform, and why analysts, customers and industry experts love SAS.\\n Artificial Intelligence trends to watch\\nQuick, watch this video to hear AI experts and data science pros weigh in on AI trends for the next decade.\\n\"}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Artificial Intelligence',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'Artificial intelligence (AI) | Definition, Examples, Types, Applications, Companies, & Facts',\n",
       "   'url': 'https://www.britannica.com/technology/artificial-intelligence',\n",
       "   'content': 'For example, a program that learns the past tense of regular English verbs by rote will not be able to produce the past tense of a word such as jump unless it previously had been presented with jumped, whereas a program that is able to generalize can learn the â€œadd edâ€ rule and so form the past tense of jump based on experience with similar verbs. The real nature of the waspâ€™s instinctual behaviour is revealed if the food is moved a few inches away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as often as the food is displaced. The program might then store the solution with the position so that the next time the computer encountered the same position it would recall the solution. Artificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the\\xa0intellectual\\xa0processes characteristic of humans, such as the ability to reason. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience.',\n",
       "   'score': 0.88372874,\n",
       "   'raw_content': 'artificial intelligence\\nOur editors will review what youâ€™ve submitted and determine whether to revise the article.\\nOur editors will review what youâ€™ve submitted and determine whether to revise the article.\\nRecent News\\nWhat is artificial intelligence?\\nArtificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the\\xa0intellectual\\xa0processes characteristic of humans, such as the ability to reason. Although there are as yet no AIs that match full human flexibility over wider domains or in tasks requiring much everyday knowledge, some AIs perform specific tasks as well as humans. Learn more.\\nAre artificial intelligence and machine learning the same?\\nNo, artificial intelligence and machine learning are not the same, but they are closely related. Machine learning is the method to train a computer to learn from its inputs but without explicit programming for every circumstance. Machine learning helps a computer to achieve artificial intelligence.\\nartificial intelligence (AI),\\nthe ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience. Since the development of the digital computer in the 1940s, it has been demonstrated that computers can be programmed to carry out very complex tasksâ€”such as discovering proofs for mathematical theorems or playing chessâ€”with great proficiency. Still, despite continuing advances in computer processing speed and memory capacity, there are as yet no programs that can match full human flexibility over wider domains or in tasks requiring much everyday knowledge. On the other hand, some programs have attained the performance levels of human experts and professionals in performing certain specific tasks, so that artificial intelligence in this limited sense is found in applications as diverse as medical diagnosis, computer search engines, voice or handwriting recognition, and chatbots.\\n(Read Ray Kurzweilâ€™s Britannica essay on the future of â€œNonbiological Man.â€)\\nWhat is intelligence?\\nAll but the simplest human behaviour is ascribed to intelligence, while even the most complicated insect behaviour is usually not taken as an indication of intelligence. What is the difference? Consider the behaviour of the digger wasp, Sphex ichneumoneus. When the female wasp returns to her burrow with food, she first deposits it on the threshold, checks for intruders inside her burrow, and only then, if the coast is clear, carries her food inside. The real nature of the waspâ€™s instinctual behaviour is revealed if the food is moved a few inches away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as often as the food is displaced. Intelligenceâ€”conspicuously absent in the case of Sphexâ€”must include the ability to adapt to new circumstances.\\n(Read Yuval Noah Harariâ€™s Britannica essay on the future of â€œNonconscious Man.â€)\\nPsychologists generally characterize human intelligence not by just one trait but by the combination of many diverse abilities. Research in AI has focused chiefly on the following components of intelligence: learning, reasoning, problem solving, perception, and using language.\\nLearning\\nThere are a number of different forms of learning as applied to artificial intelligence. The simplest is learning by trial and error. For example, a simple computer program for solving mate-in-one chess problems might try moves at random until mate is found. The program might then store the solution with the position so that the next time the computer encountered the same position it would recall the solution. This simple memorizing of individual items and proceduresâ€”known as rote learningâ€”is relatively easy to implement on a computer. More challenging is the problem of implementing what is called generalization. Generalization involves applying past experience to analogous new situations. For example, a program that learns the past tense of regular English verbs by rote will not be able to produce the past tense of a word such as jump unless it previously had been presented with jumped, whereas a program that is able to generalize can learn the â€œadd edâ€ rule and so form the past tense of jump based on experience with similar verbs.'},\n",
       "  {'title': 'What Is Artificial Intelligence (AI)? | Google Cloud',\n",
       "   'url': 'https://cloud.google.com/learn/what-is-artificial-intelligence',\n",
       "   'content': 'Solution\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nTake the next step\\nStart\\nbuilding on Google Cloud with $300 in free credits and 20+\\nalways free products.\\n Artificial intelligence (AI) is a set of technologies\\nthat enable computers to perform a variety of advanced\\nfunctions, including the ability to\\nsee,\\nunderstand and\\ntranslate spoken and written language,\\nanalyze data,\\nmake recommendations, and more.\\n Artificial intelligence\\ndefined\\nArtificial intelligence is a field of science\\nconcerned with building computers and machines that\\ncan reason, learn, and act in such a way that would\\nnormally require human intelligence or that involves\\ndata whose scale exceeds what humans can\\nanalyze.\\n By using products like\\nVertex AI,\\nCCAI,\\nDocAI,\\nor AI APIs, organizations can make sense of all the data\\ntheyâ€™re producing, collecting, or otherwise analyzing,\\nno matter what format itâ€™s in, to make actionable\\nbusiness decisions.\\n On an operational level for business use, AI is a\\nset of technologies that are based primarily on\\nmachine learning and deep learning, used for data\\nanalytics, predictions and forecasting, object\\ncategorization, natural language processing,\\nrecommendations, intelligent data retrieval, and\\nmore.\\n',\n",
       "   'score': 0.77751994,\n",
       "   'raw_content': 'What is Artificial\\nIntelligence (AI)?\\nArtificial intelligence (AI) is a set of technologies\\nthat enable computers to perform a variety of advanced\\nfunctions, including the ability to\\nsee,\\nunderstand and\\ntranslate spoken and written language,\\nanalyze data,\\nmake recommendations, and more.\\nAI is the backbone of innovation in modern computing,\\nunlocking value for individuals and businesses. For\\nexample,\\noptical character recognition (OCR)\\nuses AI to extract text and data from images and\\ndocuments, turns unstructured content into\\nbusiness-ready structured data, and unlocks valuable\\ninsights.\\nReady to get started? New customers get $300 in free\\ncredits to spend on Google Cloud.\\nArtificial intelligence\\ndefined\\nArtificial intelligence is a field of science\\nconcerned with building computers and machines that\\ncan reason, learn, and act in such a way that would\\nnormally require human intelligence or that involves\\ndata whose scale exceeds what humans can\\nanalyze.\\nAI is a broad field that encompasses many different\\ndisciplines, including computer science, data\\nanalytics and statistics, hardware and software\\nengineering, linguistics, neuroscience, and even\\nphilosophy and psychology.\\nOn an operational level for business use, AI is a\\nset of technologies that are based primarily on\\nmachine learning and deep learning, used for data\\nanalytics, predictions and forecasting, object\\ncategorization, natural language processing,\\nrecommendations, intelligent data retrieval, and\\nmore.\\nTypes of artificial\\nintelligence\\nArtificial intelligence can be organized in several ways,\\ndepending on stages of development or actions being\\nperformed.\\nFor instance, four stages of AI development are commonly\\nrecognized.\\nA more useful way of broadly categorizing types of\\nartificial intelligence is by what the machine can do. All\\nof what we currently call artificial intelligence is\\nconsidered artificial â€œnarrowâ€ intelligence, in that it can\\nperform only narrow sets of actions based on its programming\\nand training. For instance, an AI algorithm that is used for\\nobject classification wonâ€™t be able to perform natural\\nlanguage processing. Google Search is a form of narrow AI,\\nas is predictive analytics, or virtual assistants.\\nArtificial general intelligence (AGI) would be the ability\\nfor a machine to â€œsense, think, and actâ€ just like a human.\\nAGI does not currently exist. The next level would be\\nartificial superintelligence (ASI), in which the machine\\nwould be able to function in all ways superior to a\\nhuman.\\nArtificial intelligence\\ntraining models\\nWhen businesses talk about AI, they often talk about\\nâ€œtraining data.â€ But what does that mean? Remember that\\nlimited-memory artificial intelligence is AI that improves\\nover time by being trained with new data. Machine learning\\nis a\\nsubset of artificial intelligence\\nthat uses algorithms to train data to obtain results.\\nIn broad strokes, three kinds of learnings models are often\\nused in machine learning:\\nSupervised learning is a machine learning model that\\nmaps a specific input to an output using labeled training\\ndata (structured data). In simple terms, to train the\\nalgorithm to recognize pictures of cats, feed it pictures\\nlabeled as cats.\\nUnsupervised learning is a machine learning model\\nthat learns patterns based on unlabeled data (unstructured\\ndata). Unlike supervised learning, the end result is not\\nknown ahead of time. Rather, the algorithm learns\\nfrom the data, categorizing it into groups based on\\nattributes. For instance, unsupervised learning is good at\\npattern matching and descriptive modeling.\\nIn addition to supervised and unsupervised learning, a\\nmixed approach called semi-supervised learning is often\\nemployed, where only some of the data is labeled. In\\nsemi-supervised learning, an end result is known, but the\\nalgorithm must figure out how to organize and structure the\\ndata to achieve the desired results.\\nReinforcement learning is a machine learning model\\nthat can be broadly described as â€œlearn by doing.â€ An\\nâ€œagentâ€ learns to perform a defined task by trial and error\\n(a feedback loop) until its performance is within a\\ndesirable range. The agent receives positive reinforcement\\nwhen it performs the task well and negative reinforcement\\nwhen it performs poorly. An example of reinforcement\\nlearning would be teaching a robotic hand to pick up a\\nball.\\nCommon types of artificial\\nneural networks\\nA common type of training model in AI is an artificial\\nneural network, a model loosely based on the human\\nbrain.\\nA neural network is a system of artificial\\nneuronsâ€”sometimes called perceptronsâ€”that are computational\\nnodes used to classify and analyze data. The data is fed\\ninto the first layer of a neural network, with each\\nperceptron making a decision, then passing that information\\nonto multiple nodes in the next layer. Training models with\\nmore than three layers are referred to as â€œdeep neural\\nnetworksâ€ or â€œdeep learning.â€ Some modern neural networks\\nhave hundreds or thousands of layers. The output of the\\nfinal perceptrons accomplish the task set to the neural\\nnetwork, such as classify an object or find patterns in\\ndata.\\nSome of the most common types of artificial neural networks\\nyou may encounter include:\\nFeedforward neural networks (FF) are one of the\\noldest forms of neural networks, with data flowing one way\\nthrough layers of artificial neurons until the output is\\nachieved. In modern days, most feedforward neural networks\\nare considered â€œdeep feedforwardâ€ with several layers\\n(and more than one â€œhiddenâ€ layer). Feedforward neural\\nnetworks are typically paired with an error-correction\\nalgorithm called â€œbackpropagationâ€ that, in simple terms,\\nstarts with the result of the neural network and works back\\nthrough to the beginning, finding errors to improve the\\naccuracy of the neural network. Many simple but powerful\\nneural networks are deep feedforward.\\nRecurrent neural networks (RNN) differ from\\nfeedforward neural networks in that they typically use time\\nseries data or data that involves sequences. Unlike\\nfeedforward neural networks, which use weights in each node\\nof the network, recurrent neural networks have â€œmemoryâ€ of\\nwhat happened in the previous layer as contingent to the\\noutput of the current layer. For instance, when performing\\nnatural language processing, RNNs can â€œkeep in mindâ€ other\\nwords used in a sentence. RNNs are often used for speech\\nrecognition, translation, and to caption images.\\nLong/short term memory (LSTM) are an advanced form\\nof RNN that can use memory to â€œrememberâ€ what happened in\\nprevious layers. The difference between RNNs and LTSM is\\nthat LTSM can remember what happened several layers ago,\\nthrough the use of â€œmemory cells.â€ LSTM is often used in\\nspeech recognition and making predictions.\\nConvolutional neural networks (CNN) include some\\nof the most common neural networks in modern artificial\\nintelligence. Most often used in image recognition, CNNs use\\nseveral distinct layers (a convolutional layer, then a\\npooling layer) that filter different parts of an image\\nbefore putting it back together (in the fully connected\\nlayer). The earlier convolutional layers may look for simple\\nfeatures of an image such as colors and edges, before\\nlooking for more complex features in additional layers.\\nGenerative adversarial networks (GAN) involve two\\nneural networks competing against each other in a game that\\nultimately improves the accuracy of the output. One network\\n(the generator) creates examples that the other network (the\\ndiscriminator) attempts to prove true or false. GANs have\\nbeen used to create realistic images and even make art.\\nBenefits of AI\\nAutomation\\nAI can automate workflows and processes or work\\nindependently and autonomously from a human team. For\\nexample, AI can help automate aspects of cybersecurity\\nby continuously monitoring and analyzing network\\ntraffic. Similarly, a smart factory may have dozens of\\ndifferent kinds of AI in use, such as robots using\\ncomputer vision to navigate the factory floor or to\\ninspect products for defects, create digital twins, or\\nuse real-time analytics to measure efficiency and\\noutput.\\nReduce human error\\nAI can eliminate manual errors in data processing,\\nanalytics, assembly in manufacturing, and other tasks\\nthrough automation and algorithms that follow the same\\nprocesses every single time.\\nEliminate repetitive tasks\\nAI can be used to perform repetitive tasks, freeing\\nhuman capital to work on higher impact problems. AI can\\nbe used to automate processes, like verifying documents,\\ntranscribing phone calls, or answering simple customer\\nquestions like â€œwhat time do you close?â€ Robots are\\noften used to perform â€œdull, dirty, or dangerousâ€ tasks\\nin the place of a human.\\nFast and accurate\\nAI can process more information more quickly than a\\nhuman, finding patterns and discovering relationships in\\ndata that a human may miss.\\nInfinite availability\\nAI is not limited by time of day, the need for breaks,\\nor other human encumbrances. When running in the cloud,\\nAI and machine learning can be â€œalways on,â€ continuously\\nworking on its assigned tasks.\\nAccelerated research and development\\nThe ability to analyze vast amounts of data quickly can\\nlead to accelerated breakthroughs in research and\\ndevelopment. For instance, AI has been used in\\npredictive modeling of potential new pharmaceutical\\ntreatments, or to quantify the human genome.\\nSolve your business challenges with Google Cloud\\nApplications and use cases for artificial intelligence\\nSpeech recognition\\nAutomatically convert spoken speech into written text.\\nImage recognition\\nIdentify and categorize various aspects of an image.\\nTranslation\\nTranslate written or spoken words from one language\\ninto another.\\nPredictive modeling\\nMine data to forecast specific outcomes with high\\ndegrees of granularity.\\nData analytics\\nFind patterns and relationships in data for business\\nintelligence.\\nCybersecurity\\nAutonomously scan networks for cyber attacks and\\nthreats.\\nRelated products and services\\nGoogle offers a number of sophisticated artificial\\nintelligence products, solutions, and applications on a\\ntrusted cloud platform that enables businesses to easily\\nbuild and implement AI algorithms and models.\\nBy using products like\\nVertex AI,\\nCCAI,\\nDocAI,\\nor AI APIs, organizations can make sense of all the data\\ntheyâ€™re producing, collecting, or otherwise analyzing,\\nno matter what format itâ€™s in, to make actionable\\nbusiness decisions.\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nTake the next step\\nStart\\nbuilding on Google Cloud with $300 in free credits and 20+\\nalways free products.\\nTake the next step\\nStart\\nyour next project, explore interactive tutorials, and\\nmanage your account.\\nWhy Google\\nProducts and pricing\\nSolutions\\nResources\\nEngage'},\n",
       "  {'title': 'Artificial Intelligence (AI) vs. Machine Learning | Columbia AI',\n",
       "   'url': 'https://ai.engineering.columbia.edu/ai-vs-machine-learning/',\n",
       "   'content': 'Home / Artificial Intelligence (AI) vs. Machine Learning\\nArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine Learning\\nArtificial intelligence (AI) and machine learning are often used interchangeably, but machine learning is a subset of the broader category of AI.\\n Computer programmers and software developers enable computers to analyze data and solve problems â€” essentially, they create artificial intelligence systems â€” by applying tools such as:\\nBelow is a breakdown of the differences between artificial intelligence and machine learning as well as how they are being applied in organizations large and small today.\\n Put in context, artificial intelligence refers to the general ability of computers to emulate human\\xa0thought and perform tasks in real-world environments, while machine learning refers to the technologies and algorithms that enable systems to identify patterns, make decisions, and improve themselves through experience and data.\\n Artificial intelligence can help manufacturing leaders automate their business processes by applying data analytics and machine learning to applications such as the following:\\nAI and Machine Learning in Banking\\nData privacy and security are especially critical within the banking industry. Financial services leaders can keep customer data secure while increasing efficiencies using AI and machine learning in several ways:\\nAI Applications in Health Care\\nThe health care field uses huge amounts of data and increasingly relies on informatics and analytics to provide accurate, efficient health services.',\n",
       "   'score': 0.74652773,\n",
       "   'raw_content': 'Home / Artificial Intelligence (AI) vs. Machine Learning\\nArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine LearningArtificial Intelligence (AI) vs. Machine Learning\\nArtificial intelligence (AI) and machine learning are often used interchangeably, but machine learning is a subset of the broader category of AI.\\nPut in context, artificial intelligence refers to the general ability of computers to emulate human\\xa0thought and perform tasks in real-world environments, while machine learning refers to the technologies and algorithms that enable systems to identify patterns, make decisions, and improve themselves through experience and data.\\nComputer programmers and software developers enable computers to analyze data and solve problems â€” essentially, they create artificial intelligence systems â€” by applying tools such as:\\nBelow is a breakdown of the differences between artificial intelligence and machine learning as well as how they are being applied in organizations large and small today.\\nWhat Is Artificial Intelligence?\\nArtificial Intelligence is the field of developing computers and robots that are capable of behaving in ways that both mimic and go beyond human capabilities. AI-enabled programs can analyze and contextualize data to provide information or automatically trigger actions without human interference.\\nToday, artificial intelligence is at the heart of many technologies we use, including smart devices and voice assistants such as Siri on Apple devices. Companies are incorporating techniques such as natural language processing and computer vision â€” the ability for computers to use human language and interpret images \\xadâ€” to automate tasks, accelerate decision making, and enable customer conversations with chatbots.\\nWhat Is Machine Learning?\\nMachine learning is a pathway to artificial intelligence. This subcategory of AI uses algorithms to automatically learn insights and recognize patterns from data, applying that learning to make increasingly better decisions.\\nBy studying and experimenting with machine learning, programmers test the limits of how much they can improve the perception, cognition, and action of a computer system.\\nDeep learning, an advanced method of machine learning, goes a step further. Deep learning models use large neural networks â€” networks that function like a human brain to logically analyze data â€” to learn complex patterns and make predictions independent of human input.\\nHow Companies Use AI and Machine Learning\\nTo be successful in nearly any industry, organizations must be able to transform their data into actionable insight. Artificial Intelligence and machine learning give organizations the advantage of automating a variety of manual processes involving data and decision making.\\nBy incorporating AI and machine learning into their systems and strategic plans, leaders can understand and act on data-driven insights with greater speed and efficiency.\\nAI in the Manufacturing Industry\\nEfficiency is key to the success of an organization in the manufacturing industry. Artificial intelligence can help manufacturing leaders automate their business processes by applying data analytics and machine learning to applications such as the following:\\nAI and Machine Learning in Banking\\nData privacy and security are especially critical within the banking industry. Financial services leaders can keep customer data secure while increasing efficiencies using AI and machine learning in several ways:\\nAI Applications in Health Care\\nThe health care field uses huge amounts of data and increasingly relies on informatics and analytics to provide accurate, efficient health services. AI tools can help improve patient outcomes, save time, and even help providers avoid burnout by:\\nLearn more about how AI is changing the world of health care.\\nThe online Artificial Intelligence executive certificate program, offered through the Fu Foundation School of Engineering and Applied Science at Columbia University, prepares you with the skills and insights to drive AI strategy and adoption across your organization.\\nWith courses that address algorithms, machine learning, data privacy, robotics, and other AI topics, this non-credit program is designed for forward-thinking team leaders and technically proficient professionals who want to gain a deeper understanding of the applications of AI. You can complete the program in 18 months while continuing to work.\\nRequest Information\\nRequest Information\\nRequest Information'}],\n",
       " 'response_time': 2.34}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_api_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUG (**TO SOLVE**) #5: HANDLE the short-term memmory for the agent to have context also about what was [asked,answered] before\n",
    "\n",
    "\n",
    "> e.g which can be the connection between both attacks?\n",
    "\n",
    "- The LLM here should renember that in the past messages, there was one record with ``[input=\"what happened with the new orleans attack?\", output=\"...\"]``\n",
    "\n",
    "- Also we need to ensure we handle the max context windows of the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SearchQueriesParams(n_queries=2, queries=[\n",
    "        \"What is the latest in AI technology?\",\n",
    "        \"What are the top trends in web development?\",\n",
    "    ],\n",
    "                    tavily_days=[7, None],\n",
    "                    tavily_topic=[\"news\", \"general\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):\n",
    "    \"\"\"\n",
    "    Takes either a single search response or list of responses from Tavily API and formats them.\n",
    "    Limits the raw_content to approximately max_tokens_per_source.\n",
    "    include_raw_content specifies whether to include the raw_content from Tavily in the formatted string.\n",
    "    \n",
    "    Args:\n",
    "        search_response: Either:\n",
    "            - A dict with a 'results' key containing a list of search results\n",
    "            - A list of dicts, each containing search results\n",
    "            \n",
    "    Returns:\n",
    "        str: Formatted string with deduplicated sources\n",
    "    \"\"\"\n",
    "    print(\"halo\")\n",
    "    # Convert input to list of results\n",
    "    if isinstance(search_response, dict):\n",
    "        # sources_list = search_response['results']\n",
    "        sources_list = search_response.get('results', [])\n",
    "        \n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                # sources_list.extend(response['results'])\n",
    "                sources_list.extend(response.get('results', []))\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "    \n",
    "    # Deduplicate by URL\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        url = source.get('url')\n",
    "        # if source['url'] not in unique_sources:\n",
    "        #     unique_sources[source['url']] = source\n",
    "        if url and url not in unique_sources:\n",
    "            unique_sources[url] = source\n",
    "    \n",
    "    # Format output\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for i, source in enumerate(unique_sources.values(), 1):\n",
    "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if include_raw_content:\n",
    "            # Using rough estimate of 4 characters per token\n",
    "            char_limit = 1000 * 4\n",
    "            # Handle None raw_content\n",
    "            raw_content = source.get('raw_content', '')\n",
    "            if raw_content is None:\n",
    "                raw_content = ''\n",
    "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to 1000 tokens: {raw_content}\\n\\n\"\n",
    "                \n",
    "    return formatted_text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gonna generate 2 queries\n",
      "halo\n",
      "Warning: No raw_content found for source https://thenewstack.io/web-development-trends-in-2024-a-shift-back-to-simplicity/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'documents': 'Sources:\\n\\nSource Fox News AI Newsletter: Will your job survive Trumpâ€™s Gen AI revolution? - Fox News:\\n===\\nURL: https://www.foxnews.com/tech/fox-news-ai-newsletter-your-job-survive-trumps-gen-ai-revolution\\n===\\nMost relevant content from source: Fox News AI Newsletter: Will your job survive Trumpâ€™s Gen AI revolution? | Fox News Fox News Media Fox News Media Fox News FOX News Shows FOX News Go Fox News Fox News AI Newsletter: Will your job survive Trumpâ€™s Gen AI revolution? Welcome to Fox Newsâ€™ Artificial Intelligence newsletter with the latest AI technology advancements. Subscribe now to get the Fox News Artificial Intelligence Newsletter in your inbox. Fox News First Fox News Opinion Fox News Lifestyle Fox News Health Fox News Fox News Go Stay up to date on the latest AI technology advancements and learn about the challenges and opportunities AI presents now and for the future with Fox News\\xa0here. FOX News Go Fox News\\n===\\nFull source content limited to 1000 tokens: \\n\\nSource Web Development Trends in 2024: A Shift Back to Simplicity:\\n===\\nURL: https://thenewstack.io/web-development-trends-in-2024-a-shift-back-to-simplicity/\\n===\\nMost relevant content from source: Web Development Trends in 2024: A Shift Back to Simplicity - The New Stack CodeGate: Open Source Tool Secures AI Coding Assistants Dec 20th 2024 12:00pm, by Steven J. AWS Launches New AI Agents To Simplify Legacy Migrations Dec 4th 2024 11:30am, by Loraine Lawson 2025 Web Hosting Trends That Could Affect Frontend Developers Dec 19th 2024 7:00am, by Loraine Lawson We look at five web development trends of 2024, including a return to simplicity for frontend devs, AI code tools, web components, and more. Neither Astro (mentioned above) nor Svelte uses the virtual DOM approach, so developers can now choose a web framework that doesnâ€™t rely on React (although Astro still has React as an option).\\n===\\nFull source content limited to 1000 tokens:'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example function usage\n",
    "search_web({\"search_queries_params\": a})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking `narrative_graph.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"hello how are you doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 12, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b6082238-ca6f-43de-9300-de1ffe092503-0', usage_metadata={'input_tokens': 12, 'output_tokens': 34, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient, AsyncTavilyClient\n",
    "# tavily_async_client = AsyncTavilyClient()\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "from typing import Generator\n",
    "\n",
    "tavily_client = TavilyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: U.S history | Duration: 6.59 seconds\n",
      "Query 2: javier milei news | Duration: 5.30 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query_1_duration': 6.591169118881226,\n",
       " 'query_2_duration': 5.303355693817139,\n",
       " 'results': [[{'query': 'U.S history',\n",
       "    'follow_up_questions': None,\n",
       "    'answer': None,\n",
       "    'images': [],\n",
       "    'results': [{'title': 'U.S. History Primary Source Timeline - The Library of Congress',\n",
       "      'url': 'https://www.loc.gov/classroom-materials/united-states-history-primary-source-timeline/',\n",
       "      'content': \"U.S. History Primary Source Timeline | Classroom Materials at the Library of Congress | Library of Congress Search Search  Shop external link Library of Congress Classroom Materials at the Library of Congress U.S. History Primary Source Timeline Presentation U.S. History Primary Source Timeline U.S. History Primary Source Timeline Explore important topics and moments in U.S. history through historical primary sources from the Library of Congress The New Nation, 1783 - 1815 U.S. History Primary Source Timeline The New Nation, 1783 - 1815 The Library of Congress offers classroom materials and professional development to help teachers effectively use primary sources from the Library's vast digital collections in their teaching. To help your students analyze these primary sources, get a graphic organizer and guides.\",\n",
       "      'score': 0.60133666,\n",
       "      'raw_content': \"U.S. History Primary Source Timeline | Classroom Materials at the Library of Congress | Library of Congress\\nTop of page\\nSkip to main content\\n Library of Congress\\nSearch\\nSearch \\nSearch toggle\\nmenu\\n\\nDiscover\\nServices\\nVisit\\nEducation\\nConnect\\nShop external link\\nDonate\\n\\nAbout\\n\\n\\nAsk a Librarian\\n\\nHelp\\n\\nContact\\n\\n\\nSearch Online Catalog\\n\\nCopyright.gov\\nCongress.gov\\n\\nLibrary of Congress Classroom Materials at the Library of Congress U.S. History Primary Source Timeline\\nShare\\n\\n\\n\\n\\n\\nPresentation U.S. History Primary Source Timeline\\nU.S. History Primary Source Timeline\\nExplore important topics and moments in U.S. history through historical primary sources from the Library of Congress\\n\\n\\n\\nColonial Settlement, 1600s - 1763\\n\\n\\n\\nThe American Revolution, 1763 - 1783\\n\\n\\n\\nThe New Nation, 1783 - 1815\\n\\n\\n\\nNational Expansion and Reform, 1815 - 1880\\n\\n\\n\\nCivil War and Reconstruction, 1861-1877\\n\\n\\n\\nRise of Industrial America, 1876-1900\\n\\n\\n\\nProgressive Era to New Era, 1900-1929\\n\\n\\n\\nGreat Depression and World War II, 1929-1945\\n\\n\\n\\nThe Post War United States, 1945-1968\\n\\n\\nPart of\\n\\nPrimary Source Sets\\nLesson Plans\\n\\nPresentations\\n\\n\\nU.S. History Primary Source Timeline\\n\\nColonial Settlement, 1600s - 1763\\nThe American Revolution, 1763 - 1783\\nThe New Nation, 1783 - 1815\\nNational Expansion and Reform, 1815 - 1880\\nCivil War and Reconstruction, 1861-1877\\nRise of Industrial America, 1876-1900\\nProgressive Era to New Era, 1900-1929\\nGreat Depression and World War II, 1929-1945\\nThe Post War United States, 1945-1968\\n\\nAdditional Navigation\\n\\n\\nTeachers Home\\nThe Library of Congress offers classroom materials and professional development to help teachers effectively use primary sources from the Library's vast digital collections in their teaching.\\n\\n\\nAnalysis Tool & Guide\\nTo help your students analyze these primary sources, get a graphic organizer and guides.\\n\\n\\nBack to top\\nFollow Us\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTake our survey External\\n\\n\\nAccessibility\\n\\nLegal\\nInspector General\\nExternal Link Disclaimer\\nUSA.gov\\nCareers\\nContact\\nMedia\\nDonate\\n\\nShop\\n\\n\\n\\n\\n\\n\\nOpens in new window Download\"}],\n",
       "    'response_time': 5.81}],\n",
       "  [{'query': 'javier milei news',\n",
       "    'follow_up_questions': None,\n",
       "    'answer': None,\n",
       "    'images': [],\n",
       "    'results': [{'title': 'Argentinian President Javier Milei plans to attend Trump ...',\n",
       "      'url': 'https://www.cbsnews.com/news/argentina-president-javier-milei-likely-to-attend-trump-inauguration/',\n",
       "      'content': 'Argentinian President Javier Milei plans to attend Trump inauguration - CBS News CBS News 24/7 CBS Evening News CBS News Mornings CBS News Team Watch CBS News Milei, a Trump acolyte who was elected last year and describes himself as an \"anarcho-capitalist,\" on Monday posted on X a link to a news report and wrote \"Make Argentina Great Again Make America Great Again,\" adding a handshake emoji between U.S. and Argentine flag emojis. CBS News reported last week that Chinese President Xi Jinping, whom Trump personally invited to the inauguration, was unlikely to attend, according to multiple sources. More from CBS News Fin GÃ³mez is the political director for CBS News. More from CBS News CBS News App Open',\n",
       "      'score': 0.8036831,\n",
       "      'raw_content': 'Watch CBS News\\nArgentinian President Javier Milei plans to attend Trump inauguration\\n\\n    By\\n                        \\n              Fin GÃ³mez\\n\\n\\nUpdated on:  December 17, 2024 / 10:49 AM EST\\n          / CBS News\\n        \\nArgentina\\'s President Javier Milei plans to attend President-elect Donald Trump\\'s inauguration in January, a spokesperson for Milei confirmed Tuesday.\\xa0\\nA spokesperson for the Trump transition team did not reply to a request for comment.\\nMilei, a Trump acolyte who was elected last year and describes himself as an \"anarcho-capitalist,\" on Monday posted on X a link to a news report and wrote \"Make Argentina Great Again Make America Great Again,\" adding a handshake emoji between U.S. and Argentine flag emojis.\\xa0\\nBloomberg News was first to report on Milei attending the inaugural, citing an Argentine government spokesperson.\\nMilei is the first world leader expected to be in Washington for the Jan. 20 event, though arrangements are underway for others to join. CBS News reported last week that Chinese President Xi Jinping, whom Trump personally invited to the inauguration, was unlikely to attend, according to multiple sources.\\xa0\\nTrump confirmed Monday that he has exchanged letters with Xi and would \"love to have him [at the inauguration], but there\\'s been nothing much discussed\" in terms of whether he\\'ll accept the invite.\\xa0\\nTrump added that he has fielded calls from more than 100 world leaders since winning the election and, initially when asked, he said that he had not invited Ukrainian President Volodymyr Zelenskyy. However, \"if he\\'d like to come, I\\'d like to have him,\" Trump said.\\nState Department records dating back to 1874 show that no world leader has attended an American transfer-of-power ceremony. Traditionally, foreign ambassadors and their spouses represent their governments at the quadrennial event.\\nMilei met with Trump at Mar-a-Lago shortly after the November election.\\xa0\\n\\n\\nJennifer Jacobs, \\n                                                  \\n                                  Margaret Brennan and \\n                                                  \\n                                  Arden Farhi\\n                  \\n        contributed to this report. \\n      \\n\\nMore from CBS News\\nFin GÃ³mez is the political director for CBS News. Fin oversees the day-to-day political coverage for CBS News. He has covered five presidential political cycles and multiple presidential campaigns. He was formerly a member of the CBS White House unit.\\n\\nÂ© 2024 CBS Interactive Inc. All Rights Reserved.\\n\\nMore from CBS News\\nCopyright Â©2025 CBS Interactive Inc. All rights reserved.\\n'}],\n",
       "    'response_time': 4.49}]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from typing import List\n",
    "\n",
    "# Assuming `tavily_client` is already initialized\n",
    "\n",
    "def debug_tavily_search():\n",
    "    \"\"\"\n",
    "    Debugs the time taken to perform two queries using the Tavily API.\n",
    "    \"\"\"\n",
    "    # Define two dummy queries\n",
    "    search_queries = [\"U.S history\", \"javier milei news\"]\n",
    "    tavily_topic = \"general\"  # Change to 'news' if needed\n",
    "\n",
    "    # Measure the time for the first query\n",
    "    start_time_query_1 = time.time()\n",
    "    result_1 = tavily_search_sync([search_queries[0]], tavily_topic)\n",
    "    end_time_query_1 = time.time()\n",
    "\n",
    "    # Measure the time for the second query\n",
    "    start_time_query_2 = time.time()\n",
    "    result_2 = tavily_search_sync([search_queries[1]], \"nes\", 7)\n",
    "    end_time_query_2 = time.time()\n",
    "\n",
    "    # Calculate durations\n",
    "    query_1_duration = end_time_query_1 - start_time_query_1\n",
    "    query_2_duration = end_time_query_2 - start_time_query_2\n",
    "\n",
    "    # Log results\n",
    "    print(f\"Query 1: {search_queries[0]} | Duration: {query_1_duration:.2f} seconds\")\n",
    "    print(f\"Query 2: {search_queries[1]} | Duration: {query_2_duration:.2f} seconds\")\n",
    "\n",
    "    return {\n",
    "        \"query_1_duration\": query_1_duration,\n",
    "        \"query_2_duration\": query_2_duration,\n",
    "        \"results\": [result_1, result_2]\n",
    "    }\n",
    "\n",
    "# def tavily_search_sync(search_queries: List[str], tavily_topic: str, tavily_days=None):\n",
    "#     \"\"\"\n",
    "#     Performs concurrent web searches using the Tavily API.\n",
    "\n",
    "#     Args:\n",
    "#         search_queries (List[SearchQuery]): List of search queries to process\n",
    "#         tavily_topic (str): Type of search to perform ('news' or 'general')\n",
    "#         tavily_days (int) or None: Number of days to look back for news articles (only used when tavily_topic='news')\n",
    "\n",
    "#     Returns:\n",
    "#         List[dict]: List of search results from Tavily API, one per query\n",
    "\n",
    "#     Note:\n",
    "#         For news searches, each result will include articles from the last `tavily_days` days.\n",
    "#         For general searches, the time range is unrestricted.\n",
    "#     \"\"\"\n",
    "#     search_docs = []\n",
    "#     for query in search_queries:\n",
    "#         if tavily_topic == \"news\":\n",
    "#             result = tavily_client.search(  # Assuming `tavily_client` is the synchronous equivalent of `tavily_async_client`\n",
    "#                 query,\n",
    "#                 max_results=1,  # 1 #todo: ---> DECIDE THE NUMBER OF RESULTS\n",
    "#                 include_raw_content=True,\n",
    "#                 topic=\"news\",\n",
    "#                 days=tavily_days\n",
    "#             )\n",
    "#         else:\n",
    "#             result = tavily_client.search(\n",
    "#                 query,\n",
    "#                 max_results=1,  # 1 #todo: ---> DECIDE THE NUMBER OF RESULTS\n",
    "#                 include_raw_content=True,\n",
    "#                 topic=\"general\"\n",
    "#             )\n",
    "#         search_docs.append(result)\n",
    "\n",
    "#     return search_docs\n",
    "\n",
    "# Run the debug function\n",
    "debug_tavily_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'javier milei news',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.thesunchronicle.com/news/nation_world/venezuela-opposition-leader-recognized-by-us-as-election-victor-embarks-on-latin-america-tour/article_d1455eff-b811-58c3-b575-0497812c8b73.html',\n",
       "   'title': 'Venezuela opposition leader recognized by US as election victor embarks on Latin America tour - The Sun Chronicle',\n",
       "   'score': 0.78154784,\n",
       "   'published_date': 'Sat, 04 Jan 2025 15:07:33 GMT',\n",
       "   'content': \"Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei wave to supporters from the government house in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei hold hands from the government house balcony in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei wave to supporters from the government house in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei hold hands from the government house balcony in Buenos Aires, Argentina, Saturday, Jan. 4, 2025.\"}],\n",
       " 'response_time': 0.42}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_client.search(\"javier milei news\", days=7,\n",
    "                     topic=\"news\", max_results=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'javier milei news',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.thesunchronicle.com/news/nation_world/venezuela-opposition-leader-recognized-by-us-as-election-victor-embarks-on-latin-america-tour/article_d1455eff-b811-58c3-b575-0497812c8b73.html',\n",
       "   'title': 'Venezuela opposition leader recognized by US as election victor embarks on Latin America tour - The Sun Chronicle',\n",
       "   'score': 0.7817479,\n",
       "   'published_date': 'Sat, 04 Jan 2025 15:07:33 GMT',\n",
       "   'content': \"Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei wave to supporters from the government house in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei hold hands from the government house balcony in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei wave to supporters from the government house in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei hold hands from the government house balcony in Buenos Aires, Argentina, Saturday, Jan. 4, 2025.\"},\n",
       "  {'url': 'https://www.thesunchronicle.com/business/venezuela-opposition-leader-recognized-by-us-as-election-victor-embarks-on-international-tour/article_d1455eff-b811-58c3-b575-0497812c8b73.html',\n",
       "   'title': 'Venezuela opposition leader recognized by US as election victor embarks on international tour - The Sun Chronicle',\n",
       "   'score': 0.7817479,\n",
       "   'published_date': 'Sat, 04 Jan 2025 17:43:33 GMT',\n",
       "   'content': \"Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei wave to supporters from the government house in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei hold hands from the government house balcony in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei wave to supporters from the government house in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei hold hands from the government house balcony in Buenos Aires, Argentina, Saturday, Jan. 4, 2025.\"},\n",
       "  {'url': 'https://www.thesunchronicle.com/news/nation_world/venezuela-opposition-leader-recognized-by-us-as-election-victor-embarks-on-international-tour/article_d1455eff-b811-58c3-b575-0497812c8b73.html',\n",
       "   'title': 'Venezuela opposition leader recognized by US as election victor embarks on international tour - The Sun Chronicle',\n",
       "   'score': 0.7817479,\n",
       "   'published_date': 'Sat, 04 Jan 2025 18:17:37 GMT',\n",
       "   'content': \"Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei wave to supporters from the government house in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei hold hands from the government house balcony in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei wave to supporters from the government house in Buenos Aires, Argentina, Saturday, Jan. 4, 2025. Venezuela's opposition leader Edmundo Gonzalez Urrutia, center right, and Argentine President Javier Milei hold hands from the government house balcony in Buenos Aires, Argentina, Saturday, Jan. 4, 2025.\"},\n",
       "  {'url': 'https://www.batimes.com.ar/news/economy/milei-scores-win-with-us1-billion-repo-from-five-top-banks.phtml',\n",
       "   'title': 'Milei scores win with US$1-billion repo from five top banks - Buenos Aires Times',\n",
       "   'score': 0.77364457,\n",
       "   'published_date': 'Sun, 05 Jan 2025 12:47:50 GMT',\n",
       "   'content': 'Milei scores win with US$1-billion repo from five top banks | Buenos Aires Times Argentina unveiled a US$1-billion repurchase agreement with five international lenders that will help replenish foreign reserves at its Central Bank, a key victory for President Javier Milei as he works to stabilise South Americaâ€™s second-largest economy. Argentinaâ€™s Central Bank said it received offers for US$2.85 billion, and that it would pay the secure overnight financing rate plus a spread of 4.75 percent\\xa0on the repo line. In Argentina, former president Mauricio Macriâ€™s administration took on repo loans with international banks to raise billions of dollars. Milei and Economy Minister Luis Caputo have said they expect to reach a deal with the IMF within the first four months of this year and that it could include fresh funding that goes beyond the previous programmeâ€™s financing.'},\n",
       "  {'url': 'https://batimes.com.ar/news/economy/milei-scores-win-with-us1-billion-repo-from-five-top-banks.phtml',\n",
       "   'title': 'Milei scores win with US$1-billion repo from five top banks - Buenos Aires Times',\n",
       "   'score': 0.77364457,\n",
       "   'published_date': 'Sun, 05 Jan 2025 12:47:50 GMT',\n",
       "   'content': 'Milei scores win with US$1-billion repo from five top banks | Buenos Aires Times Argentina unveiled a US$1-billion repurchase agreement with five international lenders that will help replenish foreign reserves at its Central Bank, a key victory for President Javier Milei as he works to stabilise South Americaâ€™s second-largest economy. Argentinaâ€™s Central Bank said it received offers for US$2.85 billion, and that it would pay the secure overnight financing rate plus a spread of 4.75 percent\\xa0on the repo line. In Argentina, former president Mauricio Macriâ€™s administration took on repo loans with international banks to raise billions of dollars. Milei and Economy Minister Luis Caputo have said they expect to reach a deal with the IMF within the first four months of this year and that it could include fresh funding that goes beyond the previous programmeâ€™s financing.'}],\n",
       " 'response_time': 0.41}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_client.search(\"javier milei news\", days=7,\n",
    "                     topic=\"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dog\n",
      "1 cat\n"
     ]
    }
   ],
   "source": [
    "for i, num in enumerate([\"dog\", \"cat\"]):\n",
    "    \n",
    "    print(i, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tavily_search_sync(search_queries:List[str], tavily_topics:List[str], tavily_days=List[Union[str, None]]):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    search_docs = []\n",
    "\n",
    "    \n",
    "    for ix, query in enumerate(search_queries):\n",
    "        \n",
    "        # print(query)\n",
    "        if tavily_topics[ix] == \"news\":\n",
    "            \n",
    "            # print(\"gonna search \", tavily_topics[ix])\n",
    "            result = tavily_client.search(  \n",
    "                query,\n",
    "                days=tavily_days[ix], #always 7 (for now)\n",
    "                topic=\"news\", \n",
    "                max_results=1 #todo: ---> DECIDE THE NUMBER OF RESULTS\n",
    "                # include_raw_content=True,\n",
    "               \n",
    "            )\n",
    "        else:\n",
    "            result = tavily_client.search(  \n",
    "                query,\n",
    "                topic=\"general\", \n",
    "                max_results=1 #todo: ---> DECIDE THE NUMBER OF RESULTS\n",
    "                # include_raw_content=True,\n",
    "               \n",
    "            )\n",
    "            \n",
    "        search_docs.append(result)\n",
    "\n",
    "    return search_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'last updates new orleans attack',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.theguardian.com/us-news/live/2025/jan/03/new-orleans-truck-attack-latest-updates',\n",
       "   'title': 'New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates - The Guardian US',\n",
       "   'score': 0.8055255,\n",
       "   'published_date': 'Fri, 03 Jan 2025 12:03:50 GMT',\n",
       "   'content': 'New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates | New Orleans truck attack | The Guardian US edition View all News View all Opinion The Guardian view View all Sport View all Culture View all Lifestyle The Guardian app New Orleans truck attack New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates This is the Guardianâ€™s latest blog on the developments after the deadly truck attack in New Orleans during the early hours of New Yearâ€™s Day. Authorities are continuing to investigate the path to radicalization of the suspect, Shamsud-Din Jabbar, a 42-year-old Texas native who once served in Afghanistan. New Orleans truck attack Most viewed Most viewed'}],\n",
       " 'response_time': 0.32}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_client.search(  \n",
    "                \"last updates new orleans attack\",\n",
    "                days=7, #always 7 (for now)\n",
    "                topic=\"news\", \n",
    "                max_results=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tavily_search_sync([\"last updates new orleans attack\", \"tesla news\"], [\"news\", \"news\"], [7, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halo\n"
     ]
    }
   ],
   "source": [
    "result = deduplicate_and_format_sources(response, max_tokens_per_source=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sources:\\n\\nSource New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates - The Guardian US:\\n===\\nURL: https://www.theguardian.com/us-news/live/2025/jan/03/new-orleans-truck-attack-latest-updates\\n===\\nMost relevant content from source: New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates | New Orleans truck attack | The Guardian US edition View all News View all Opinion The Guardian view View all Sport View all Culture View all Lifestyle The Guardian app New Orleans truck attack New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates This is the Guardianâ€™s latest blog on the developments after the deadly truck attack in New Orleans during the early hours of New Yearâ€™s Day. Authorities are continuing to investigate the path to radicalization of the suspect, Shamsud-Din Jabbar, a 42-year-old Texas native who once served in Afghanistan. New Orleans truck attack Most viewed Most viewed\\n===\\nFull source content limited to 10000 tokens: \\n\\nSource DC History Center: Home:\\n===\\nURL: https://dchistory.org/\\n===\\nMost relevant content from source: The DC History Center is a 501(c)3 educational nonprofit that deepens understanding of our city's past to connect, empower, and inspire.\\n===\\nFull source content limited to 10000 tokens:\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Tavily Web Search'}, page_content=\"Sources:\\n\\nSource New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates - The Guardian US:\\n===\\nURL: https://www.theguardian.com/us-news/live/2025/jan/03/new-orleans-truck-attack-latest-updates\\n===\\nMost relevant content from source: New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates | New Orleans truck attack | The Guardian US edition View all News View all Opinion The Guardian view View all Sport View all Culture View all Lifestyle The Guardian app New Orleans truck attack New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates This is the Guardianâ€™s latest blog on the developments after the deadly truck attack in New Orleans during the early hours of New Yearâ€™s Day. Authorities are continuing to investigate the path to radicalization of the suspect, Shamsud-Din Jabbar, a 42-year-old Texas native who once served in Afghanistan. New Orleans truck attack Most viewed Most viewed\\n===\\nFull source content limited to 10000 tokens: \\n\\nSource DC History Center: Home:\\n===\\nURL: https://dchistory.org/\\n===\\nMost relevant content from source: The DC History Center is a 501(c)3 educational nonprofit that deepens understanding of our city's past to connect, empower, and inspire.\\n===\\nFull source content limited to 10000 tokens:\")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document(page_content=result,\n",
    "                           \n",
    "                        metadata={\"source\": \"Tavily Web Search\"} )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'last updates new orleans attack',\n",
       "  'follow_up_questions': None,\n",
       "  'answer': None,\n",
       "  'images': [],\n",
       "  'results': [{'url': 'https://www.theguardian.com/us-news/live/2025/jan/03/new-orleans-truck-attack-latest-updates',\n",
       "    'title': 'New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates - The Guardian US',\n",
       "    'score': 0.8055255,\n",
       "    'published_date': 'Fri, 03 Jan 2025 12:03:50 GMT',\n",
       "    'content': 'New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates | New Orleans truck attack | The Guardian US edition View all News View all Opinion The Guardian view View all Sport View all Culture View all Lifestyle The Guardian app New Orleans truck attack New Orleans truck attack: investigations continue into suspectâ€™s path to radicalization â€“ latest updates This is the Guardianâ€™s latest blog on the developments after the deadly truck attack in New Orleans during the early hours of New Yearâ€™s Day. Authorities are continuing to investigate the path to radicalization of the suspect, Shamsud-Din Jabbar, a 42-year-old Texas native who once served in Afghanistan. New Orleans truck attack Most viewed Most viewed'}],\n",
       "  'response_time': 0.31},\n",
       " {'query': 'washington d.c history',\n",
       "  'follow_up_questions': None,\n",
       "  'answer': None,\n",
       "  'images': [],\n",
       "  'results': [{'title': 'DC History Center: Home',\n",
       "    'url': 'https://dchistory.org/',\n",
       "    'content': \"The DC History Center is a 501(c)3 educational nonprofit that deepens understanding of our city's past to connect, empower, and inspire.\",\n",
       "    'score': 0.7316155,\n",
       "    'raw_content': None}],\n",
       "  'response_time': 2.61}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):\n",
    "    \"\"\"\n",
    "    Takes either a single search response or list of responses from Tavily API and formats them.\n",
    "    Limits the raw_content to approximately max_tokens_per_source.\n",
    "    include_raw_content specifies whether to include the raw_content from Tavily in the formatted string.\n",
    "    \n",
    "    Args:\n",
    "        search_response: Either:\n",
    "            - A dict with a 'results' key containing a list of search results\n",
    "            - A list of dicts, each containing search results\n",
    "            \n",
    "    Returns:\n",
    "        str: Formatted string with deduplicated sources\n",
    "    \"\"\"\n",
    "    # Convert input to list of results\n",
    "    if isinstance(search_response, dict):\n",
    "        # sources_list = search_response['results']\n",
    "        sources_list = search_response.get('results', [])\n",
    "        \n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                # sources_list.extend(response['results'])\n",
    "                sources_list.extend(response.get('results', []))\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "    \n",
    "    # Deduplicate by URL\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        url = source.get('url')\n",
    "        # if source['url'] not in unique_sources:\n",
    "        #     unique_sources[source['url']] = source\n",
    "        if url and url not in unique_sources:\n",
    "            unique_sources[url] = source\n",
    "    \n",
    "    # Format output\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for i, source in enumerate(unique_sources.values(), 1):\n",
    "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if include_raw_content:\n",
    "            # Using rough estimate of 4 characters per token\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            # Handle None raw_content\n",
    "            raw_content = source.get('raw_content', '')\n",
    "            if raw_content is None:\n",
    "                raw_content = ''\n",
    "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
    "                \n",
    "    return formatted_text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicate_and_format_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(state):\n",
    "    \"\"\" Web search based based on the question.\"\"\"\n",
    "    \n",
    "    # Get search_queries_params from state (which includes lists of queries, tavily_topic, and tavily_days)\n",
    "     \n",
    "    search_queries_params = state[\"search_queries_params\"]\n",
    "    n_queries = search_queries_params.n_queries  # Number of queries to generate\n",
    "    queries = search_queries_params.queries  # List of queries\n",
    "    tavily_topics = search_queries_params.tavily_topic  # List of topics ('news' or 'general')\n",
    "    tavily_days = search_queries_params.tavily_days  # List of days for limiting search (or None)\n",
    "\n",
    "    print(f\"gonna generate {n_queries} queries\")\n",
    "    # Check if lengths of queries, tavily_topics, and tavily_days are equal\n",
    "    if not (n_queries == len(queries) == len(tavily_topics) == len(tavily_days)):\n",
    "        raise ValueError(\"The lengths of queries, tavily_topics, and tavily_days must be equal.\")\n",
    "    \n",
    "    # Web search using async function with corresponding parameters\n",
    "    # for query, topic, days in zip(queries, tavily_topics, tavily_days):\n",
    "    #     search_doc = tavily_search_sync([query], topic, days)  # Replace with synchronous function\n",
    "    #     search_docs.extend(search_doc)  # Add results to the overall list\n",
    "\n",
    "    response = tavily_search_sync(search_queries=queries, tavily_topics=tavily_topics, tavily_days=tavily_days)\n",
    "    \n",
    "    \n",
    "    # Deduplicate and format sources                                             #1000 -- check annotations whasap\n",
    "    source_str = deduplicate_and_format_sources(response, max_tokens_per_source=5000, include_raw_content=True)\n",
    "\n",
    "    web_results = Document(page_content=source_str,\n",
    "                           \n",
    "                        metadata={\"source\": \"Tavily Web Search\"} )\n",
    "    \n",
    "    #we'll also add to the vectorstore the websearch results so next time it won't need to run web search again for specific questions\n",
    "    vectorstore.add_documents([web_results])\n",
    "    \n",
    "    return {\"documents\": web_results.page_content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_curator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
